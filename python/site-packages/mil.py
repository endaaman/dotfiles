import os
import cv2
import matplotlib
from matplotlib import pyplot as plt
from pydantic import Field
from sklearn import metrics
import numpy as np
import torch
from torch import nn
import torch.nn.functional as F
from torchvision import datasets, transforms
from timm.scheduler import CosineLRScheduler

from endaaman.ml import BaseMLCLI, BaseDLArgs, BaseTrainer, BaseTrainerConfig, Checkpoint
from endaaman.metrics import BaseMetrics, AccuracyByChannel


J = os.path.join


class MILModel(nn.Module):
    def __init__(self, params_count=64, num_classes=1):
        super().__init__()
        self.params_count = params_count
        self.num_classes = num_classes
        self.convs = nn.Sequential(
            nn.Conv2d(1, 32, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 32, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 16, 3, 1, 1),
            nn.ReLU(inplace=True),
        )
        self.pool = nn.AdaptiveAvgPool2d((4, 4))
        self.num_features = 16 * 16
        self.fc = nn.Linear(self.num_features, self.num_classes)

        self.u = nn.Linear(self.num_features, self.params_count, bias=False)
        self.v = nn.Linear(self.num_features, self.params_count, bias=False)
        self.w = nn.Linear(self.params_count, 1, bias=False)


    def compute_attention_scores(self, x):
        # P,
        xu = torch.tanh(self.u(x))
        # P,
        xv = torch.sigmoid(self.v(x))
        # P -> 1
        alpha = self.w(xu * xv)
        return alpha

    def compute_attentions(self, features):
        aa = []
        for feature in features:
            # feature: F
            aa.append(self.compute_attention_scores(feature))
        aa = torch.stack(aa).flatten()
        aa = torch.softmax(aa, dim=0)
        return aa

    def forward(self, x, activate=False, with_attentions=False):
        x = self.convs(x)
        x = self.pool(x)
        features = torch.flatten(x, 1)

        # B x F
        aa = self.compute_attentions(features)
        feature = (features * aa[:, None]).sum(dim=0)
        y = self.fc(feature)

        if activate:
            if self.num_classes > 1:
                y = torch.softmax(y, dim=1)
            else:
                y = torch.sigmoid(y)

        if with_attentions:
            return y, aa.detach()
        return y

class SAModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.convs = nn.Sequential(
            nn.Conv2d(1, 32, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 32, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 16, 3, 1, 1),
            nn.ReLU(inplace=True),
        )
        self.pool = nn.AdaptiveAvgPool2d((4, 4))
        num_features = 16 * 4 * 4
        self.fc = nn.Linear(num_features, 1)

        self.emb_q = nn.Linear(num_features, num_features, bias=False)
        self.emb_k = nn.Linear(num_features, num_features, bias=False)

    def forward(self, x, activate=False, with_attentions=False):
        x = self.convs(x)
        x = self.pool(x)
        features = torch.flatten(x, 1)

        q = self.emb_q(features)
        k = self.emb_k(features)

        qk = q @ k.transpose(1, 0)
        qk = torch.softmax(qk, 1)
        attentions = qk.sum(0) / len(features)

        feature = (features * attentions[..., None]).sum(dim=0)
        y = self.fc(feature)

        if activate:
            y = torch.sigmoid(y)

        if with_attentions:
            return y, attentions.detach()
        return y



class AccMetrics(BaseMetrics):
    def calc(self, preds, gts):
        gts = gts.reshape(preds.shape[0], -1)
        preds = preds.flatten() > 0.5
        gts = torch.any(gts == 0, dim=1)[None]
        return torch.sum(preds == gts) / len(preds)


class ROCMetrics(BaseMetrics):
    def calc(self, preds, gts):
        if len(preds) < 2:
            return None
        gts = gts.reshape(preds.shape[0], -1)
        gts = torch.any(gts == 0, dim=1)
        fpr, tpr, __thresholds = metrics.roc_curve(gts.numpy(), preds.numpy())
        auc = metrics.auc(fpr, tpr)
        youden_index = np.argmax(tpr - fpr)
        return auc, tpr[youden_index], -fpr[youden_index]+1


class TrainerConfig(BaseTrainerConfig):
    mode:str = 'mean'
    attention: str = 'mil'

class Trainer(BaseTrainer):
    def prepare(self):
        if self.config.attention == 'mil':
            model = MILModel()
        else:
            model = SAModel()
        self.criterion = nn.BCELoss()
        # self.criterion = nn.CrossEntropyLoss()
        return model

    def eval(self, inputs, gts):
        pred = self.model(inputs.to(self.device), activate=True)
        gts = torch.any(gts == 0).float()[None]
        loss = self.criterion(pred, gts.to(self.device))
        return loss, pred[None].cpu().detach()

    def get_metrics(self):
        return {
            # 'acc': AccMetrics(),
            'auc_recall_spec': ROCMetrics(),
        }

class CLI(BaseMLCLI):
    class TrainArgs(BaseDLArgs):
        epoch:int = 20
        batch_size:int = 8
        overwrite: bool = Field(False, cli=('--overwrite', '-O'))
        attention: str = Field('mil', cli=('--attention', '-A'))

    def run_train(self, a:TrainArgs):
        dss = [datasets.MNIST(
            root='./datasets/MNIST',
            train=t,
            download=True,
            transform=transforms.ToTensor(),
        ) for t in [True, False] ]

        dss[0].data = dss[0].data[:10000, ...]
        dss[1].data = dss[1].data[:1000, ...]

        config = TrainerConfig(
            batch_size=a.batch_size,
            lr=0.001,
            num_workers=a.num_workers,
            attention=a.attention,
        )

        t = Trainer(
            config=config,
            out_dir=f'out/models/{a.attention}',
            train_dataset=dss[0],
            val_dataset=dss[1],
            use_gpu=not a.cpu,
            overwrite=a.overwrite,
        )
        t.start(a.epoch)

    class PredArgs(BaseMLCLI.CommonArgs):
        model_dir:str = Field(..., cli=('--model-dir', '-M'))
        count:int = 10

    def run_pred(self, a:PredArgs):
        chp_path = J(a.model_dir, 'checkpoint_best.pt')
        c:Checkpoint = torch.load(chp_path)
        config = TrainerConfig.from_file(J(a.model_dir, 'config.json'))
        ds = datasets.MNIST(
            root='./datasets/MNIST',
            train=False,
            download=True,
            transform=transforms.ToTensor(),
        )
        if config.attention == 'mil':
            M = MILModel
        else:
            M = SAModel
        model = M()
        model.load_state_dict(c.model_state)

        idx = np.random.choice(ds.data.shape[0], a.count)
        x = ds.data[idx][:, None, :, :] / 255
        # gt = ds.targets[idx]

        y, aa = model(x, activate=True, with_attentions=True)

        plt.subplot(2,1,1)
        plt.title(f'pred: {y.item():.3f}')
        plt.imshow(cv2.hconcat(x.numpy().squeeze()))
        plt.subplot(2,1,2)
        plt.pcolor([aa.numpy()])
        plt.savefig(J(a.model_dir, f'{a.count}_{a.seed}.png'))
        plt.show()

    def run_model(self, a):
        model = SAModel()

        x = torch.randn(9, 1, 28, 28)
        y, aa = model(x, activate=True)
        print(y)
        print(y.shape)


if __name__ == '__main__':
    cli = CLI()
    cli.run()
