import os
import sys

import timm
import numpy as np
from sklearn.metrics import confusion_matrix
import torch
from torch import nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from torch.utils.data import Dataset
from pydantic import Field
from matplotlib import pyplot as plt
from tqdm import tqdm
from umap import UMAP
import albumentations as A

from endaaman.ml import BaseTrainer, BaseTrainerConfig, tensor_to_pil, pil_to_tensor, Checkpoint
from endaaman.ml.cli2 import BaseMLCLI, BaseDLArgs
from endaaman.ml.metrics import BaseMetrics, AccuracyByChannel


J = os.path.join


class PairDatgaset(Dataset):
    def __init__(self, is_train:bool, dual:bool=False, augself:bool=True):
        self.ds = datasets.MNIST(
            './datasets/MNIST',
            train = is_train,
            download = True,
        )
        self.dual = dual
        self.augself = augself

        self.aug = A.Compose([
            A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=20, p=1.0),
            # A.ElasticTransform(p=1, alpha=12, sigma=5, alpha_affine=5),
        ])

    def __len__(self):
        return len(self.ds.data)

    def __getitem__(self, i):
        x = self.ds.data[i].numpy()
        y = x
        if self.augself:
            x = self.aug(image=x)['image']
        y = self.aug(image=x)['image']
        x = torch.from_numpy(x[None, ...]/255).to(torch.float32)
        y = torch.from_numpy(y[None, ...]/255).to(torch.float32)

        if self.dual:
            same = (torch.rand(1) > 0.5)[0]
            if not same:
                i = torch.randint(len(self.ds.data), (1, ))[0]
                y = self.ds.data[i].numpy()
                y = self.aug(image=y)['image']
                y = torch.from_numpy(y[None, ...]/255).to(torch.float32)
            return x, y, same

        return x, y


class IICModel(nn.Module):
    def __init__(self, model_name, input_size=1, num_cluster=10, num_over_cluster=100):
        super().__init__()
        self.num_cluster = num_cluster
        self.num_over_cluster = num_over_cluster
        self.model_name = model_name

        self.base = timm.create_model(
                model_name=model_name,
                pretrained=False,
                num_classes=10,
                in_chans=input_size)

        # num_features = 16 * 16
        num_features = 512
        self.fc = nn.Linear(num_features, num_cluster)
        self.fc_over = nn.Linear(num_features, num_over_cluster)

    def forward(self, x, activate=False):
        x = self.base.forward_features(x)
        features = self.base.global_pool(x)
        y = self.fc(features)
        y_over = self.fc_over(features)
        if activate:
            y = torch.softmax(y, dim=-1)
            y_over = torch.softmax(y_over, dim=-1)
            # y = torch.sigmoid(y)
            # y_over = torch.sigmoid(y_over)
        return y, y_over


class IICLoss(nn.Module):
    def __init__(self, alpha):
        super().__init__()
        self.alpha = alpha

    def forward(self, i, j):
        EPS = sys.float_info.epsilon
        bs, k = i.size()
        p_i_j = i.unsqueeze(2) * j.unsqueeze(1)
        p_i_j = p_i_j.sum(dim=0)
        p_i_j = (p_i_j + p_i_j.t()) / 2.0
        p_i_j = p_i_j / p_i_j.sum()

        p_i_j = torch.clamp(p_i_j, min=EPS)

        p_i = p_i_j.sum(dim=1).view(k, 1).expand(k, k)
        p_j = p_i_j.sum(dim=0).view(1, k).expand(k, k)

        loss = p_i_j * (self.alpha*torch.log(p_j) + self.alpha*torch.log(p_i) - torch.log(p_i_j))
        loss = loss.sum()
        return loss

class DualLoss(nn.Module):
    def __init__(self, alpha):
        super().__init__()
        self.alpha = alpha

    def forward(self, xx, yy, sames):
        EPS = sys.float_info.epsilon
        losses = []
        for x, y, same in zip(xx, yy, sames):
            # pxy = - torch.sum(x * torch.log(y+EPS))
            # pyx = - torch.sum(y * torch.log(x+EPS))
            # loss = pxy + pyx
            if same:
                pxy = - torch.mean(x * torch.log(y+EPS))
                pyx = - torch.mean(y * torch.log(x+EPS))
                loss = (pxy + pyx)/2
            else:
                loss = - torch.mean(torch.log(x) * torch.log(y) / torch.log(x * y))
                loss *= self.alpha
            # print(True, loss)
            losses.append(loss)
        return sum(losses) / len(losses)


class CrossEntropyLoss(nn.Module):
    def __init__(self, eps=1e-32, input_logits=True):
        super().__init__()
        self.eps = eps
        self.input_logits = input_logits

    # y: target index
    def forward(self, x, y):
        if self.input_logits:
            x = torch.softmax(x, dim=-1)
        return F.nll_loss(torch.clamp(x, self.eps).log(), y)


class TrainerConfig(BaseTrainerConfig):
    model_name:str
    num_cluster:int = 10
    num_over_cluster:int = 100
    dual: bool = False
    augself: bool = False
    alpha: float= 2.0


class Trainer(BaseTrainer):
    # def metrics_acc(self, preds, gts):
    #     correct = torch.sum(torch.argmax(preds, dim=-1) == gts)
    #     return correct / len(preds)

    # def _visualize_confusion(self, ax, label, preds, gts):
    #     preds = torch.argmax(preds, dim=-1)
    #     cm = confusion_matrix(gts.numpy(), preds.numpy())
    #     sns.heatmap(cm, annot=True, ax=ax, fmt='g')
    #     ax.set_title(label)
    #     ax.set_xlabel('Predict', fontsize=13)
    #     ax.set_ylabel('GT', fontsize=13)

    # def visualize_train_confusion(self, ax, train_preds, train_gts, val_preds, val_gts):
    #     self._visualize_confusion(ax, 'train', train_preds, train_gts)

    # def visualize_val_confusion(self, ax, train_preds, train_gts, val_preds, val_gts):
    #     self._visualize_confusion(ax, 'val', val_preds, val_gts)

    def prepare(self):
        model = IICModel(
            input_size=1,
            model_name=self.config.model_name,
            num_cluster=self.config.num_cluster,
            num_over_cluster=self.config.num_over_cluster
        )
        # self.criterion = CrossEntropyLoss(input_logits=False)
        if self.config.dual:
            Loss = DualLoss
        else:
            Loss = IICLoss
        self.criterion = Loss(alpha=self.config.alpha)
        return model

    def eval(self, *args):
        if self.config.dual:
            xx, yy, sames = args
        else:
            xx, yy = args
        x_pred, x_pred_over = self.model(xx.to(self.device), activate=True)
        y_pred, y_pred_over = self.model(yy.to(self.device), activate=True)

        if self.config.dual:
            loss = self.criterion(x_pred, y_pred, sames)
            loss_over = self.criterion(x_pred_over, y_pred_over, sames)
        else:
            loss = self.criterion(x_pred, y_pred)
            loss_over = self.criterion(x_pred_over, y_pred_over)
        total_loss = (loss + loss_over) / 2
        # total_loss = loss
        return total_loss, None


class CLI(BaseMLCLI):
    class CommonArgs(BaseMLCLI.CommonArgs):
        pass

    def run_model(self, a):
        x = torch.randn(4, 1, 28, 28)
        model = IICModel(x)
        y, y0 = model(x)
        print(y.shape, y0.shape)

    class TrainArgs(CommonArgs):
        lr:float = 0.001
        epoch: int = Field(50, s='-E')
        model_name: str = Field('resnet18', s='-m', l='--model')
        num_workers: int = 4
        batch_size: int = Field(32, s='-B')
        dual: bool = False
        augself: bool = False
        dual: bool = False
        suffix: str = Field('', s='-S')
        overwrite:bool = Field(False, s='-O')
        alpha:float = 2.0

    def run_train(self, a:TrainArgs):
        dss = [
            PairDatgaset(is_train='train'==t, dual=a.dual, augself=a.augself)
            for t in [True, False]
        ]

        config = TrainerConfig(
            lr=a.lr,
            model_name=a.model_name,
            batch_size=a.batch_size,
            num_workers=a.num_workers,
            dual=a.dual,
            augself=a.augself,
            alpha=a.alpha,
        )

        name = self.with_suffix('dual' if a.dual else 'iic', a.suffix)

        t = Trainer(
            loss_fmt='{:.10f}',
            config=config,
            out_dir=f'out/models/{name}',
            train_dataset=dss[0],
            val_dataset=dss[1],
            overwrite=a.overwrite,
            fig_size=(20, 8),
            fig_col_count=2,
        )
        t.start(a.epoch)

    class PredArgs(BaseDLArgs):
        model_dir: str = Field(..., s='-d')
        show: bool = False

    def run_pred(self, a):
        checkpoint = Checkpoint.from_file(J(a.model_dir, 'checkpoint_last.pt'))
        config = TrainerConfig.from_file(J(a.model_dir, 'config.json'))
        model = IICModel(model_name=config.model_name)
        model.load_state_dict(checkpoint.model_state)
        model = model.eval()

        ds = datasets.MNIST(
            './datasets/MNIST',
            train = False,
            download = True,
            transform = transforms.Compose([
                transforms.ToTensor(),
            ])
        )

        pairs = []
        preds = []

        for i in tqdm(range(1000)):
            x, gt = ds.__getitem__(i)
            x = x[None, ...]
            with torch.no_grad():
                pred, y_o = model(x, activate=True)
            # pred = y_o
            p = torch.argmax(pred)
            pairs.append((gt, p.item()))
            preds.append(pred.detach().numpy()[0])
            # plt.imshow(x.squeeze())
            # plt.show()

        pairs = np.array(pairs)
        gts = pairs[:, 0]
        ps = pairs[:, 1]
        preds = np.stack(preds)

        print(preds.shape)

        U_gt, C_gt = np.unique(pairs[:, 0], return_counts=True)
        U_pred, C_pred = np.unique(pairs[:, 1], return_counts=True)

        print(np.asarray((U_gt, C_gt)).T)
        print(np.asarray((U_pred, C_pred)).T)

        embedding = UMAP().fit_transform(preds)
        embedding_x = embedding[:, 0]
        embedding_y = embedding[:, 1]
        print('done cluster')

        fig, ax = plt.subplots(1, 1, figsize=(14, 10))
        # for p, gt, x, y in zip(ps, gts, embedding_x, embedding_y):
        #     plt.scatter(x, y, s=24, label=gt+1)

        for gt in np.unique(gts):
            needle = gts == gt
            plt.scatter(embedding_x[needle], embedding_y[needle], s=5, label=gt)

        plt.legend()
        plt.show()


    class LossArgs(CommonArgs):
        pass

    def loss(self, x, y, same):
        if same:
            return - torch.sum(x * torch.log(y) + y * torch.log(x))
        # return torch.sum(x * y)
        return torch.sum(x * torch.log(1-y) + y * torch.log(1-x))

    def run_loss(self, a):
        x = torch.tensor([0.1, 0.9])
        y = torch.tensor([0.3, 0.7])
        z = torch.tensor([0.9, 0.1])

        print('same', x, y)
        print(self.loss(x, y, True))

        print('diff', x, y)
        print(self.loss(x, y, False))

        print('same', x, z)
        print(self.loss(x, z, True))

        print('diff', x, z)
        print(self.loss(x, z, False))

    def run_aug(self, a):
        ds = datasets.MNIST(
            './datasets/MNIST',
            train = False,
            download = True,
        )
        xx = ds.data[:10].numpy()

        aug = A.Compose([
            A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=30, p=1.0),
            A.ElasticTransform(p=1, alpha=3, sigma=5, alpha_affine=5),
            # A.OneOf([
            #     A.CLAHE(clip_limit=2),
            #     A.Emboss(),
            #     # A.RandomBrightnessContrast(brightness_limit=0.1),
            #     A.RandomToneCurve(),
            #     A.MotionBlur(),
            # ], p=1.0),
        ])

        xx2 = []
        xx3 = []
        for x in xx:
            xx2.append(aug(image=x)['image'])
            xx3.append(aug(image=x)['image'])
        xx = np.concatenate(xx, axis=1)
        xx2 = np.concatenate(xx2, axis=1)
        xx3 = np.concatenate(xx3, axis=1)
        print(xx.shape)
        print(xx2.shape)
        plt.imshow(np.concatenate([xx, xx2, xx3], axis=0))
        plt.show()



print('enter done')

if __name__ == '__main__':
    cli = CLI()
    cli.run()
