import os
import sys

import timm
import numpy as np
import cv2
from sklearn.metrics import confusion_matrix
import torch
from torch import nn
import torch.nn.functional as F
from torch import optim
from torch.utils.data import Dataset
from torchvision import datasets, transforms
from pydantic import Field
import matplotlib as mpl
from matplotlib import pyplot as plt
from matplotlib.offsetbox import OffsetImage, AnnotationBbox
from tqdm import tqdm
from umap import UMAP
import albumentations as A
from albumentations.pytorch.transforms import ToTensorV2

from endaaman.ml import BaseTrainer, BaseTrainerConfig, tensor_to_pil, pil_to_tensor, Checkpoint
from endaaman.ml.cli import BaseMLCLI, BaseDLArgs
from endaaman.ml.metrics import BaseMetrics, AccuracyByChannel


J = os.path.join

def pack(l):
    return [e for e in l if e]


def create_dataset(mode, is_train, normalization, **kwargs):
    if mode == 'mnist':
        ds = datasets.MNIST(
            './datasets/MNIST',
            train = is_train,
            download = True,
            **kwargs,
        )
        data = ds.data.numpy()[:, None, :, :]
        labels = ds.targets
        albu = A.Compose([
            A.ShiftScaleRotate(
                shift_limit=(-0.1, 0.1), scale_limit=(-0.1, 0.1),
                rotate_limit=(-10, 10), p=1.0
            ),
            # A.ElasticTransform(p=1.0, alpha=1, sigma=3, alpha_affine=3),
            ToTensorV2(),
        ])
        aug_train = lambda x: albu(image=x.squeeze())['image']/255
        # aug_test = transforms.Compose([
        #     transforms.ToTensor()
        # ])
        aug_test = lambda x: torch.from_numpy(x/255).to(torch.float32)
        return data, labels, aug_train, aug_test
    if mode == 'fashion':
        ds = datasets.FashionMNIST(
            './datasets/FashionMNIST/',
            train = is_train,
            download = True,
            **kwargs,
        )
        data = ds.data.numpy()[:, None, :, :]
        labels = ds.targets
        albu = A.Compose([
            A.ShiftScaleRotate(
                shift_limit=(-0.3, 0.3), scale_limit=(-0.1, 0.1),
                rotate_limit=(-10, 10), p=1.0
            ),
            A.OneOf([
                A.ElasticTransform(p=1.0, alpha=3, sigma=3, alpha_affine=1),
                A.Blur(p=1.0),
            ], p=1.0),
        ])
        aug_train = lambda x: albu(image=x.squeeze())['image']
        aug_test = lambda x: torch.from_numpy(x/255).to(torch.float32).permute(2, 0, 1)
        return data, labels, aug_train, aug_test
    if mode == 'cifar10':
        ds = datasets.CIFAR10(
            './datasets/CIFAR10/',
            train = is_train,
            download = True,
            **kwargs,
        )
        data = ds.data
        labels = torch.tensor(ds.targets)
        norm_args = dict(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))
        albu = A.Compose(pack([
            # A.Rotate(limit=10),
            # A.RandomResizedCrop(
                #     height=32, width=32,
                #     scale=(0.8, 1.25),
                # ),
            # A.ShiftScaleRotate(
                #     shift_limit=(-0.2, 0.2), scale_limit=(-0.2, 0.2),
                #     rotate_limit=(-10, 10), p=0.8
                # ),
            # A.ElasticTransform(p=1.0, alpha=1, sigma=1, alpha_affine=1),
            A.HorizontalFlip(p=0.5),
            A.ShiftScaleRotate(
                shift_limit=(-0.2, 0.2), scale_limit=(-0.1, 0.1),
                rotate_limit=(-10, 10), p=1.0
                ),
            A.OneOf([
                A.HueSaturationValue(p=1.0,),
                A.RGBShift(p=1.0),
                A.MultiplicativeNoise(p=1.0),
            ], p=1.0),
            A.ElasticTransform(p=1.0, alpha=1, sigma=3, alpha_affine=3),
            # A.OneOf([
            #     A.ElasticTransform(p=1.0, alpha=3, sigma=3, alpha_affine=1),
            #     A.Blur(p=1.0),
            #     A.OpticalDistortion(p=1.0),
            # ], p=1.0),
            A.Normalize(**norm_args) if normalization else None,
            ToTensorV2(),
        ]))
        aug_train = lambda x: albu(image=x.squeeze())['image']
        aug_test = transforms.Compose(pack([
            transforms.ToTensor(),
            transforms.Normalize(**norm_args) if normalization else None,
        ]))
        return data, labels, aug_train, aug_test
    raise RuntimeError('Invalid dataset', dataset)


IN_CHANS_MAP = {
    'mnist': 1,
    'fashion': 1,
    'cifar10': 3,
}

class IICDatgaset(Dataset):
    def __init__(self, dataset:str, is_train:bool, normalization:bool=True):
        self.dataset = dataset
        self.is_train = is_train
        self.normalization = normalization
        self.data, self.labels, self.aug_train, self.aug_test = create_dataset(
            dataset,
            is_train,
            normalization
        )

    def __len__(self):
        return len(self.data)

    def __getitem__(self, i):
        base = self.data[i]
        label = self.labels[i]
        x = self.aug_test(base)
        y = self.aug_train(base)
        return x, y, label


def get_pool(m):
    if hasattr(m, 'global_pool'):
        return m.global_pool
    return m.head.global_pool

class TimmModel(nn.Module):
    def __init__(self, model_name, input_size=1, num_cluster=10, num_over_cluster=-1):
        super().__init__()
        self.num_cluster = num_cluster
        self.num_over_cluster = num_over_cluster
        self.model_name = model_name

        self.base = timm.create_model(
            model_name=model_name,
            pretrained=False,
            num_classes=10,
            in_chans=input_size,
        )

        # num_features = 16 * 16
        self.num_features = self.base.num_features
        self.pool = get_pool(self.base)
        self.fc = nn.Linear(self.num_features, num_cluster)
        if num_over_cluster > 0:
            self.fc_over = nn.Linear(self.num_features, num_over_cluster)

    def activate(self, logit):
        if logit.shape[-1] == 0:
            return torch.sigmoid(logit)
        return torch.softmax(logit, dim=-1)

    def forward(self, x):
        x = self.base.forward_features(x)
        features = self.pool(x).view(x.shape[0], self.num_features)
        logit = self.fc(features)
        p = self.activate(logit)

        logit_over = None
        p_over = None
        if self.num_over_cluster > 0:
            logit_over = self.fc_over(features)
            p_over = self.activate(logit_over)

        return {
            'features': features,
            'logit': logit,
            'logit_over': logit_over,
            'p': p,
            'p_over': p_over,
        }


class IICLoss(nn.Module):
    def __init__(self, alpha, beta=0.0):
        super().__init__()
        self.alpha = alpha
        self.beta = beta

    def forward(self, p, q):
        EPS = sys.float_info.epsilon
        bs, k = p.size()

        # J: Joint prob
        J = p.unsqueeze(2) * q.unsqueeze(1)
        J = torch.clamp(J, min=EPS)
        J = J.mean(dim=0)
        J = (J + J.t()) / 2.0

        r = (p + q) / 2.0
        M1 = r.mean(dim=0).view(k, 1).expand(k, k)
        M2 = M1.t()
        M = M1 * M2

        S1 = r.std(dim=0).view(k, 1).expand(k, k)
        S2 = S1.t()
        S = S1 * S2

        a, b = self.alpha, self.beta
        loss = J * (a*M.log() - b*S.log() - J.log())
        return loss.sum()



class NTXentLoss(nn.Module):
    def __init__(self, temperature):
        super().__init__()
        self.temperature = temperature

    def forward(self, z_i, z_j):
        batch_size = z_i.size(0)
        print('z_i')
        print(z_i)
        print('z_j')
        print(z_j)

        similarity_matrix = torch.matmul(z_i, z_j.T)
        print('similarity_matrix')
        print(similarity_matrix.shape)
        print(similarity_matrix)

        sim_ij = torch.diag(similarity_matrix)
        print('sim_ij')
        print(sim_ij.shape)
        print(sim_ij)

        sim_i_all = torch.sum(torch.exp(similarity_matrix / self.temperature), dim=1)
        print('sim_i_all')
        print(sim_i_all.shape)
        print(sim_i_all)

        loss = torch.sum(-torch.log(torch.exp(sim_ij / self.temperature) / sim_i_all))
        print('loss')
        print(loss)

        exit()
        return loss / batch_size


class CommonTrainerConfig(BaseTrainerConfig):
    lr:float = 0.001
    model_name: str = Field('resnet18', s='-m', l='--model')
    batch_size: int = Field(512, s='-B')
    dataset:str = Field('mnist', choices=['mnist', 'fashion', 'cifar10'], s='-d')

class IICTrainerConfig(CommonTrainerConfig):
    num_cluster:int = 10
    num_over_cluster:int = 20
    alpha:float = 2.0
    beta:float = 0.1

class SimCLRTrainerConfig(CommonTrainerConfig):
    temp: float = 1.0


class IICTrainer(BaseTrainer):
    def prepare(self):
        model = TimmModel(
            input_size=IN_CHANS_MAP[self.config.dataset],
            model_name=self.config.model_name,
            num_cluster=self.config.num_cluster,
            num_over_cluster=self.config.num_over_cluster
        )
        self.criterion = IICLoss(alpha=self.config.alpha, beta=self.config.beta)
        return model

    def metrics_precision(self, preds, gts, batch):
        if batch:
            return None
        preds = preds.detach().cpu()
        labels = torch.unique(preds)
        correct = 0
        for label in labels:
            items = gts[preds == label]
            elements, counts = torch.unique(items, return_counts=True)
            dominant = elements[torch.argmax(counts)]
            # print(label, dominant, torch.sum(items == dominant))
            correct += torch.sum(items == dominant)
        return correct/len(preds)

    def create_scheduler(self):
        return optim.lr_scheduler.StepLR(self.optimizer, step_size=20, gamma=0.1)
        # return optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, patience=10)
        # return optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=20, eta_min=self.config.lr/100)

    def select_inputs_and_gts(self, params):
        return params[0], params[2]

    def eval(self, *args):
        xx, yy, __labels, __iter = args
        x_result = self.model(xx.to(self.device))
        y_result = self.model(yy.to(self.device))
        x_pred, x_pred_over = x_result['p'], x_result['p_over']
        y_pred, y_pred_over = y_result['p'], y_result['p_over']

        loss = self.criterion(x_pred, y_pred)
        loss_over = self.criterion(x_pred_over, y_pred_over)
        loss = (loss + loss_over) / 2
        return loss, torch.argmax(x_pred, dim=1)

class SimCLRTrainer(BaseTrainer):
    def prepare(self):
        model = TimmModel(
            input_size=IN_CHANS_MAP[self.config.dataset],
            model_name=self.config.model_name,
            num_cluster=256,
            num_over_cluster=-1
        )
        self.criterion = NTXentLoss(temperature=self.config.temp)
        return model

    def create_scheduler(self):
        return optim.lr_scheduler.StepLR(self.optimizer, step_size=20, gamma=0.1)

    def eval(self, *args):
        xx, yy, __labels, __iter = args
        x_result = self.model(xx.to(self.device))
        y_result = self.model(yy.to(self.device))
        x = x_result['logit']
        y = y_result['logit']

        loss = self.criterion(x, y)
        return loss, None


class CLI(BaseMLCLI):
    class CommonArgs(BaseMLCLI.CommonArgs):
        pass

    class CommonTrainArgs(CommonArgs):
        overwrite:bool = Field(False, s='-O')
        name: str = Field('{}', s='-n')
        num_workers: int = 4
        epoch: int = Field(50, s='-E')

    def run_model(self, a):
        x = torch.randn(4, 1, 28, 28)
        model = IICModel(x)
        y, y0 = model(x)

    class IicArgs(CommonTrainArgs, IICTrainerConfig):
        pass

    def run_iic(self, a:IicArgs):
        dss = [
            IICDatgaset(dataset=a.dataset, is_train='train'==t)
            for t in [True, False]
        ]

        config = IICTrainerConfig(**a.dict())

        t = IICTrainer(
            config=config,
            out_dir=f'out/iic/{a.dataset}/{a.name.format(a.model_name)}',
            train_dataset=dss[0],
            val_dataset=dss[1],
            overwrite=a.overwrite,
            fig_size=(20, 8),
            fig_col_count=2,
        )
        t.start(a.epoch)

    class SimclrArgs(CommonTrainArgs, SimCLRTrainerConfig):
        pass

    def run_simclr(self, a:SimclrArgs):
        dss = [
            IICDatgaset(dataset=a.dataset, is_train='train'==t)
            for t in [True, False]
        ]

        config = SimCLRTrainerConfig(**a.dict())

        t = SimCLRTrainer(
            config=config,
            out_dir=f'out/simclr/{a.dataset}/{a.name.format(a.model_name)}',
            train_dataset=dss[0],
            val_dataset=dss[1],
            overwrite=a.overwrite,
            fig_size=(20, 8),
            fig_col_count=2,
        )
        t.start(a.epoch)

    class ClusterArgs(BaseDLArgs):
        model_dir: str = Field(..., s='-d')
        show: bool = False
        limit: int = 1000

    def run_cluster(self, a):
        checkpoint = Checkpoint.from_file(J(a.model_dir, 'checkpoint_last.pt'))
        config = IICTrainerConfig.from_file(J(a.model_dir, 'config.json'))

        ds = IICDatgaset(
            config.dataset,
            is_train=False,
        )

        images = ds.data[:a.limit]
        print(config)
        P1 = J(a.model_dir, 'pairs.npy')
        P2 = J(a.model_dir, 'preds.npy')
        if os.path.exists(P1) and os.path.exists(P2):
            pairs = np.load(J(a.model_dir, 'pairs.npy'))
            preds = np.load(J(a.model_dir, 'preds.npy'))
            gts = pairs[:, 0]
        else:
            model = TimmModel(
                model_name=config.model_name,
                input_size=IN_CHANS_MAP[config.dataset],
                num_cluster=config.num_cluster,
                num_over_cluster=config.num_over_cluster,
            )
            model.load_state_dict(checkpoint.model_state)
            model = model.eval()

            pairs = []
            preds = []

            for i in tqdm(range(a.limit)):
                x, y, gt = ds.__getitem__(i)
                with torch.no_grad():
                    r = model(x[None, ...])
                    pred, p_over = r['p'], r['p_over']
                # pred = y_o
                p = torch.argmax(pred)
                pairs.append((gt, p.item()))
                preds.append(pred.detach().numpy()[0])
                # plt.imshow(x.squeeze())
                # plt.show()

            pairs = np.array(pairs)
            gts = pairs[:, 0]
            ps = pairs[:, 1]
            preds = np.stack(preds)
            np.save(self.with_wrote(J(a.model_dir, 'pairs')), pairs)
            np.save(self.with_wrote(J(a.model_dir, 'preds')), preds)


        U_gt, C_gt = np.unique(pairs[:, 0], return_counts=True)
        U_pred, C_pred = np.unique(pairs[:, 1], return_counts=True)

        print(np.asarray((U_gt, C_gt)).T)
        print(np.asarray((U_pred, C_pred)).T)

        embedding = UMAP(n_neighbors=10, densmap=True).fit_transform(preds)
        embedding_x = embedding[:, 0]
        embedding_y = embedding[:, 1]
        print('done cluster')

        fig, ax = plt.subplots(1, 1, figsize=(14, 10))
        scs = []
        iis = []
        print(gts.shape)
        print(images.shape)
        for gt in np.unique(gts):
            needle = gts == gt
            # print(needle)
            scs.append(plt.scatter(embedding_x[needle], embedding_y[needle], s=5, label=gt))
            ii = [cv2.resize(i.squeeze(), (224, 224)) for i in images[needle]]
            iis.append(ii)


        imagebox = OffsetImage(images[0][0], zoom=.5)
        imagebox.image.axes = ax
        annot = AnnotationBbox(
                imagebox,
                xy=(0, 0),
                # xybox=(256, 256),
                # xycoords='data',
                boxcoords='offset points',
                # boxcoords=('axes fraction', 'data'),
                pad=0.1,
                arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=-0.3'))
        annot.set_visible(False)
        ax.add_artist(annot)

        def hover(event):
            vis = annot.get_visible()
            if event.inaxes != ax:
                return
            for n, (sc, ii) in enumerate(zip(scs, iis)):
                cont, index = sc.contains(event)
                if cont:
                    i = index['ind'][0]
                    pos = sc.get_offsets()[i]
                    annot.xy = pos
                    annot.xybox = pos + np.array([150, 30])
                    image = ii[i]
                    # text = unique_code[n]
                    # annot.set_text(text)
                    # annot.get_bbox_patch().set_facecolor(cmap(int(text)/10))
                    imagebox.set_data(image)
                    annot.set_visible(True)
                    fig.canvas.draw_idle()
                    return

            if vis:
                annot.set_visible(False)
                fig.canvas.draw_idle()
                return

        fig.canvas.mpl_connect('motion_notify_event', hover)
        fig.canvas.manager.set_window_title(a.model_dir)

        plt.savefig(J(a.model_dir, 'cluster.png'))
        plt.legend()
        if a.show:
            plt.show()


    class LossArgs(CommonArgs):
        pass

    def loss(self, x, y, same):
        if same:
            return - torch.sum(x * torch.log(y) + y * torch.log(x))
        # return torch.sum(x * y)
        return torch.sum(x * torch.log(1-y) + y * torch.log(1-x))

    def run_loss(self, a):
        x = torch.tensor([0.1, 0.9])
        y = torch.tensor([0.3, 0.7])
        z = torch.tensor([0.9, 0.1])

        print('same', x, y)
        print(self.loss(x, y, True))

        print('diff', x, y)
        print(self.loss(x, y, False))

        print('same', x, z)
        print(self.loss(x, z, True))

        print('diff', x, z)
        print(self.loss(x, z, False))

    class AugArgs(CommonArgs):
        dataset:str = Field('mnist', choices=['mnist', 'fashion', 'cifar10'], s='-d')
        count:int = 10
        start:int = 0

    def run_aug(self, a):
        # mpl.use('TkAgg')
        ds = IICDatgaset(dataset=a.dataset, is_train=True, normalization=False)
        x0s = []
        x1s = []
        xx = []
        i = a.start
        for x0, x1, label in ds:
            # x0s.append(x0)
            # x1s.append(x1)
            x1 = x1/255
            c = np.concatenate([x0.numpy(), x1.numpy()], axis=1).squeeze()
            xx.append(c)
            if i > a.start+a.count:
                break
            i += 1
        xxx = np.concatenate(xx, axis=-1)
        if len(xxx.shape) > 2:
            xxx = xxx.transpose(1, 2, 0)
        plt.imshow(xxx)
        plt.xticks([])
        plt.yticks([])
        os.makedirs('out/iic/aug_example', exist_ok=True)
        plt.savefig(f'out/iic/aug_example/{a.dataset}_{a.start}_{a.start+a.count}.png')
        plt.show()



print('enter done')

if __name__ == '__main__':
    cli = CLI()
    cli.run()
