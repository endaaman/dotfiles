import os
import sys

import timm
import numpy as np
import cv2
from sklearn.metrics import confusion_matrix
import torch
from torch import nn
import torch.nn.functional as F
from torchvision import datasets, transforms
from torch.utils.data import Dataset
from pydantic import Field
from matplotlib import pyplot as plt
from matplotlib.offsetbox import OffsetImage, AnnotationBbox
from tqdm import tqdm
from umap import UMAP
import albumentations as A

from endaaman.ml import BaseTrainer, BaseTrainerConfig, tensor_to_pil, pil_to_tensor, Checkpoint
from endaaman.ml.cli import BaseMLCLI, BaseDLArgs
from endaaman.ml.metrics import BaseMetrics, AccuracyByChannel


J = os.path.join


def create_mnist_dataset(mode, is_train, **kwargs):
    if mode == 'number':
        ds = datasets.MNIST(
            './datasets/MNIST',
            train = is_train,
            download = True,
            **kwargs,
        )
        data = ds.data.numpy()[:, None, :, :]
        labels = ds.targets
        aug = A.Compose([
            A.ShiftScaleRotate(
                shift_limit=(-0.1, 0.1), scale_limit=(-0.1, 0.1),
                rotate_limit=(-10, 10), p=1.0
            ),
            A.ElasticTransform(p=1.0, alpha=1, sigma=3, alpha_affine=3),
        ])
        return data, labels, aug
    if mode == 'fashion':
        ds = datasets.FashionMNIST(
            './datasets/FashionMNIST/',
            train = is_train,
            download = True,
            **kwargs,
        )
        data = ds.data.numpy()[:, None, :, :]
        labels = ds.targets
        aug = A.Compose([
            A.ShiftScaleRotate(
                shift_limit=(-0.3, 0.3), scale_limit=(-0.1, 0.1),
                rotate_limit=(-10, 10), p=1.0
            ),
            A.OneOf([
                A.ElasticTransform(p=1.0, alpha=3, sigma=3, alpha_affine=1),
                A.Blur(p=1.0),
            ], p=1.0),
        ])
        return data, labels, aug
    if mode == 'cifar10':
        ds = datasets.CIFAR10(
            './datasets/CIFAR10/',
            train = is_train,
            download = True,
            **kwargs,
        )
        data = ds.data
        labels = torch.tensor(ds.targets)
        aug = A.Compose([
            A.RandomResizedCrop(
                height=32, width=32,
                scale=(0.66, 1.5),
            ),
            A.Rotate(limit=30),
            # A.ShiftScaleRotate(
            #     shift_limit=0, scale_limit=0,
            #     rotate_limit=(-10, 10), p=1.0
            # ),
            # A.ElasticTransform(p=1.0, alpha=1, sigma=1, alpha_affine=1),
            A.HorizontalFlip(p=0.5),

            A.OneOf([
                A.HueSaturationValue(p=1.0,),
                A.RGBShift(p=1.0),
            ], p=1.0),

            A.OneOf([
                A.ElasticTransform(p=1.0, alpha=3, sigma=3, alpha_affine=1),
                A.Blur(p=1.0),
                A.OpticalDistortion(p=1.0),
            ], p=1.0),
        ])
        return data, labels, aug
    raise RuntimeError('Invalid dataset', dataset)

IN_CHANS_MAP = {
    'number': 1,
    'fashion': 1,
    'cifar10': 3,
}

class IICDatgaset(Dataset):
    def __init__(self, dataset:str, is_train:bool, dual:bool):
        self.dataset = dataset
        self.dual = dual
        self.data, self.labels, self.aug = create_mnist_dataset(dataset, is_train)

    def __len__(self):
        return len(self.ds.data)

    def __getitem__(self, i):
        x = self.data[i]
        y = x
        label = self.labels[i]
        if self.dual:
            x = self.aug(image=x)['image']
        # else:
        #     x = self.resize(image=x)['image']
        y = self.aug(image=x)['image']

        # HWC->CHW
        x = torch.from_numpy(x/255).to(torch.float32).permute(2, 0, 1)
        y = torch.from_numpy(y/255).to(torch.float32).permute(2, 0, 1)
        return x, y, label


def get_pool(m):
    if hasattr(m, 'global_pool'):
        return m.global_pool
    return m.head.global_pool

class IICModel(nn.Module):
    def __init__(self, model_name, input_size=1, num_cluster=10, num_over_cluster=100):
        super().__init__()
        self.num_cluster = num_cluster
        self.num_over_cluster = num_over_cluster
        self.model_name = model_name

        self.base = timm.create_model(
            model_name=model_name,
            pretrained=False,
            num_classes=10,
            in_chans=input_size,
        )

        # num_features = 16 * 16
        self.num_features = self.base.num_features
        self.pool = get_pool(self.base)
        self.fc = nn.Linear(self.num_features, num_cluster)
        self.fc_over = nn.Linear(self.num_features, num_over_cluster)

    def forward(self, x, activate=False):
        x = self.base.forward_features(x)
        features = self.pool(x).view(x.shape[0], self.num_features)
        y = self.fc(features)
        y_over = self.fc_over(features)
        if activate:
            y = torch.softmax(y, dim=-1)
            y_over = torch.softmax(y_over, dim=-1)
            # y = torch.sigmoid(y)
            # y_over = torch.sigmoid(y_over)
        return y, y_over


class IICLoss(nn.Module):
    def __init__(self, alpha, beta=0.0):
        super().__init__()
        self.alpha = alpha
        self.beta = beta

    def forward(self, p, q):
        EPS = sys.float_info.epsilon
        bs, k = p.size()

        p = torch.clamp(p, min=EPS)
        q = torch.clamp(q, min=EPS)

        # J: Joint prob
        J = p.unsqueeze(2) * q.unsqueeze(1)
        J = J.sum(dim=0)
        J = (J + J.t()) / 2.0 / J.sum()

        # Mean by channel
        r = (p + q) / 2.0

        # Pm, Qm: mean terms
        M1 = r.mean(dim=0).view(k, 1).expand(k, k)
        M2 = M1.t()
        # Pm = J.sum(dim=1).view(k, 1).expand(k, k)
        # Qm = J.sum(dim=0).view(1, k).expand(k, k)

        # Ps, Qs: std terms
        S1 = r.std(dim=0).view(k, 1).expand(k, k)
        S2 = S1.t()

        a = self.alpha
        b = self.beta

        loss = J * (a*M1.log() + a*M2.log() - b*S1.log() - b*S2.log() - J.log() )
        loss = loss.sum()
        return loss

class CrossEntropyLoss(nn.Module):
    def __init__(self, eps=1e-32, input_logits=True):
        super().__init__()
        self.eps = eps
        self.input_logits = input_logits

    # y: target index
    def forward(self, x, y):
        if self.input_logits:
            x = torch.softmax(x, dim=-1)
        return F.nll_loss(torch.clamp(x, self.eps).log(), y)


class TrainerConfig(BaseTrainerConfig):
    model_name:str
    num_cluster:int = 10
    num_over_cluster:int = 100
    dataset:str='number'
    dual:bool = False
    alpha:float= 2.0
    beta:float= 0.1


class Trainer(BaseTrainer):
    def metrics_precision(self, preds, gts, batch):
        if batch:
            return None
        preds = preds.detach().cpu()
        labels = torch.unique(preds)
        correct = 0
        for label in labels:
            items = gts[preds == label]
            elements, counts = torch.unique(items, return_counts=True)
            dominant = elements[torch.argmax(counts)]
            # print(label, dominant, torch.sum(items == dominant))
            correct += torch.sum(items == dominant)
        return correct/len(preds)
        # return correct / len(preds)

    # def _visualize_confusion(self, ax, label, preds, gts):
    #     # preds = torch.argmax(preds, dim=-1)
    #     # cm = confusion_matrix(gts.numpy(), preds.numpy())
    #     # sns.heatmap(cm, annot=True, ax=ax, fmt='g')
    #     # ax.set_title(label)
    #     x = np.arange(100)
    #     y = x ** 2
    #     ax.plot(x, y)
    #     ax.set_xlabel('Predict', fontsize=13)
    #     ax.set_ylabel('GT', fontsize=13)

    # def visualize_train_acc(self, ax, train_preds, train_gts, val_preds, val_gts):
    #     self._visualize_confusion(ax, 'train', train_preds, train_gts)

    # def visualize_val_acc(self, ax, train_preds, train_gts, val_preds, val_gts):
    #     self._visualize_confusion(ax, 'val', val_preds, val_gts)

    def prepare(self):
        model = IICModel(
            input_size=IN_CHANS_MAP[self.config.dataset],
            model_name=self.config.model_name,
            num_cluster=self.config.num_cluster,
            num_over_cluster=self.config.num_over_cluster
        )
        # self.criterion = CrossEntropyLoss(input_logits=False)
        self.criterion = IICLoss(alpha=self.config.alpha, beta=self.config.beta)
        return model

    def select_inputs_and_gts(self, params):
        return params[0], params[2]

    def eval(self, *args):
        xx, yy, __labels = args
        x_pred, x_pred_over = self.model(xx.to(self.device), activate=True)
        y_pred, y_pred_over = self.model(yy.to(self.device), activate=True)

        loss = self.criterion(x_pred, y_pred)
        loss_over = self.criterion(x_pred_over, y_pred_over)
        total_loss = (loss + loss_over) / 2
        # total_loss = loss
        return total_loss, torch.argmax(x_pred, dim=1)


class CLI(BaseMLCLI):
    class CommonArgs(BaseMLCLI.CommonArgs):
        pass

    def run_model(self, a):
        x = torch.randn(4, 1, 28, 28)
        model = IICModel(x)
        y, y0 = model(x)

    class TrainArgs(CommonArgs):
        lr:float = 0.001
        epoch: int = Field(50, s='-E')
        model_name: str = Field('resnet18', s='-m', l='--model')
        num_workers: int = 4
        batch_size: int = Field(512, s='-B')
        num_cluster:int = 10
        dual: bool = False
        name: str = Field('{}', s='-n')
        overwrite:bool = Field(False, s='-O')
        alpha:float = 2.0
        beta:float = 0.0
        size:int = 28

        dataset:str = Field('number', choices=['number', 'fashion', 'cifar10'], s='-d')

    def run_train(self, a:TrainArgs):
        dss = [
            IICDatgaset(dataset=a.dataset, is_train='train'==t, dual=a.dual)
            for t in [True, False]
        ]

        config = TrainerConfig(
            lr=a.lr,
            model_name=a.model_name,
            num_cluster=a.num_cluster,
            batch_size=a.batch_size,
            num_workers=a.num_workers,
            dataset=a.dataset,
            dual=a.dual,
            alpha=a.alpha,
            beta=a.beta,
            size=a.size,
        )


        d = a.name.format('iic')

        t = Trainer(
            # loss_fmt='{:.10f}',
            config=config,
            out_dir=f'out/iic/{a.dataset}/{d}',
            train_dataset=dss[0],
            val_dataset=dss[1],
            overwrite=a.overwrite,
            fig_size=(20, 8),
            fig_col_count=2,
        )
        t.start(a.epoch)

    class ClusterArgs(BaseDLArgs):
        model_dir: str = Field(..., s='-d')
        show: bool = False
        limit: int = 1000

    def run_cluster(self, a):
        checkpoint = Checkpoint.from_file(J(a.model_dir, 'checkpoint_last.pt'))
        config = TrainerConfig.from_file(J(a.model_dir, 'config.json'))
        model = IICModel(model_name=config.model_name)
        model.load_state_dict(checkpoint.model_state)
        model = model.eval()

        ds = create_mnist_dataset(
            config.dataset,
            is_train=False,
            transform = transforms.Compose([
                transforms.ToTensor(),
            ])
        )

        pairs = []
        preds = []

        images = ds.data[:a.limit].numpy()

        for i in tqdm(range(a.limit)):
            x, gt = ds.__getitem__(i)
            with torch.no_grad():
                pred, y_o = model(x, activate=True)
            # pred = y_o
            p = torch.argmax(pred)
            pairs.append((gt, p.item()))
            preds.append(pred.detach().numpy()[0])
            # plt.imshow(x.squeeze())
            # plt.show()

        pairs = np.array(pairs)
        gts = pairs[:, 0]
        ps = pairs[:, 1]
        preds = np.stack(preds)

        np.save(self.with_wrote(J(a.model_dir, 'pairs')), pairs)

        print(preds.shape)

        U_gt, C_gt = np.unique(pairs[:, 0], return_counts=True)
        U_pred, C_pred = np.unique(pairs[:, 1], return_counts=True)

        print(np.asarray((U_gt, C_gt)).T)
        print(np.asarray((U_pred, C_pred)).T)

        embedding = UMAP(n_neighbors=30).fit_transform(preds)
        embedding_x = embedding[:, 0]
        embedding_y = embedding[:, 1]
        print('done cluster')

        fig, ax = plt.subplots(1, 1, figsize=(14, 10))
        scs = []
        iis = []
        print(gts.shape)
        print(images.shape)
        for gt in np.unique(gts):
            needle = gts == gt
            # print(needle)
            scs.append(plt.scatter(embedding_x[needle], embedding_y[needle], s=5, label=gt))
            ii = [cv2.resize(i[..., None], (140, 140)) for i in images[needle]]
            iis.append(ii)


        imagebox = OffsetImage(images[0], zoom=.5)
        imagebox.image.axes = ax
        annot = AnnotationBbox(
                imagebox,
                xy=(0, 0),
                # xybox=(256, 256),
                # xycoords='data',
                boxcoords='offset points',
                # boxcoords=('axes fraction', 'data'),
                pad=0.1,
                arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=-0.3'))
        annot.set_visible(False)
        ax.add_artist(annot)

        def hover(event):
            vis = annot.get_visible()
            if event.inaxes != ax:
                return
            for n, (sc, ii) in enumerate(zip(scs, iis)):
                cont, index = sc.contains(event)
                if cont:
                    i = index['ind'][0]
                    pos = sc.get_offsets()[i]
                    annot.xy = pos
                    annot.xybox = pos + np.array([150, 30])
                    image = ii[i]
                    # text = unique_code[n]
                    # annot.set_text(text)
                    # annot.get_bbox_patch().set_facecolor(cmap(int(text)/10))
                    imagebox.set_data(image)
                    annot.set_visible(True)
                    fig.canvas.draw_idle()
                    return

            if vis:
                annot.set_visible(False)
                fig.canvas.draw_idle()
                return

        fig.canvas.mpl_connect('motion_notify_event', hover)


        plt.legend()
        plt.show()


    class LossArgs(CommonArgs):
        pass

    def loss(self, x, y, same):
        if same:
            return - torch.sum(x * torch.log(y) + y * torch.log(x))
        # return torch.sum(x * y)
        return torch.sum(x * torch.log(1-y) + y * torch.log(1-x))

    def run_loss(self, a):
        x = torch.tensor([0.1, 0.9])
        y = torch.tensor([0.3, 0.7])
        z = torch.tensor([0.9, 0.1])

        print('same', x, y)
        print(self.loss(x, y, True))

        print('diff', x, y)
        print(self.loss(x, y, False))

        print('same', x, z)
        print(self.loss(x, z, True))

        print('diff', x, z)
        print(self.loss(x, z, False))

    class AugArgs(CommonArgs):
        dataset:str = Field('number', choices=['number', 'fashion', 'cifar10'], s='-d')
        num:int = 5

    def run_aug(self, a):
        ds = IICDatgaset(dataset=a.dataset, is_train=False, dual=False)
        xx = ds.data[:20]

        xxx = []
        xxx.append(np.concatenate(xx, axis=1))
        for i in range(a.num):
            xx_aug = []
            for x in xx:
                xx_aug.append(ds.aug(image=x)['image'])
            xx_aug = np.concatenate(xx_aug, axis=1)
            xxx.append(xx_aug)
        xxx = np.concatenate(xxx, axis=0)
        print(xxx.shape)
        plt.imshow(xxx)
        plt.show()



print('enter done')

if __name__ == '__main__':
    cli = CLI()
    cli.run()
