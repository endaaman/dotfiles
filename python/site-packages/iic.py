import sys

import numpy as np
from sklearn.metrics import confusion_matrix
import seaborn as sns
import torch
import torchvision as tv
from torch import nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from timm.scheduler import CosineLRScheduler
from pydantic import Field

from endaaman.ml import BaseMLCLI, BaseTrainer, BaseTrainerConfig, tensor_to_pil, pil_to_tensor
from endaaman.ml.metrics import BaseMetrics, AccuracyByChannel



class IICModel(nn.Module):
    def __init__(self, input_size=1, num_cluster=10, num_over_cluster=100):
        super().__init__()
        self.num_cluster = num_cluster
        self.num_over_cluster = num_over_cluster

        self.convs = nn.Sequential(
            nn.Conv2d(1, 32, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 32, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 16, 3, 1, 1),
            nn.ReLU(inplace=True),
        )
        self.pool = nn.AdaptiveAvgPool2d((4, 4))

        self.fc = nn.Linear(16 * 16, num_cluster)
        self.fc_over = nn.Linear(16 * 16, num_over_cluster)

    def forward(self, x, activate=False):
        x = self.convs(x)
        x = self.pool(x)
        features = torch.flatten(x, 1)
        y = self.fc(features)
        y_over = self.fc_over(features)

        if activate:
            y = F.softmax(y, dim=1)
            y_over = F.softmax(y_over, dim=1)
        return y, y_over


def perturb_imagedata(x):
    y = x.clone()
    batch_size = x.size(0)

    # ランダムなアフィン変換を実施
    trans = tv.transforms.RandomAffine(15, (0.2, 0.2,), (0.2, 0.75,))
    for i in range(batch_size):
        y[i, 0] = pil_to_tensor(trans(tensor_to_pil(y[i, 0])))

    # ノイズを加える
    noise = torch.randn(batch_size, 1, x.size(2), x.size(3))
    div = torch.randint(20, 30, (batch_size,),
                        dtype=torch.float32).view(batch_size, 1, 1, 1)
    y += noise / div

    return y

def compute_joint(x_out, x_tf_out):

    # x_out、x_tf_outは torch.Size([512, 10])。この二つをかけ算して同時分布を求める、torch.Size([2048, 10, 10])にする。
    # torch.Size([512, 10, 1]) * torch.Size([512, 1, 10])
    p_i_j = x_out.unsqueeze(2) * x_tf_out.unsqueeze(1)
    # p_i_j は　torch.Size([512, 10, 10])

    # 全ミニバッチを足し算する ⇒ torch.Size([10, 10])
    p_i_j = p_i_j.sum(dim=0)

    # 転置行列と足し算して割り算（対称化） ⇒ torch.Size([10, 10])
    p_i_j = (p_i_j + p_i_j.t()) / 2.

    # 規格化 ⇒ torch.Size([10, 10])
    p_i_j = p_i_j / p_i_j.sum()

    return p_i_j
    # 結局、p_i_jは通常画像の判定出力10種類と、変換画像の判定10種類の100パターンに対して、全ミニバッチが100パターンのどれだったのかの確率分布表を示す


def iid_loss(x_out, x_tf_out, EPS=sys.float_info.epsilon):
    # torch.Size([512, 10])、後ろの10は分類数なので、overclusteringのときは100
    bs, k = x_out.size()
    p_i_j = compute_joint(x_out, x_tf_out)  # torch.Size([10, 10])

    # 同時確率の分布表から、変換画像の10パターンをsumをして周辺化し、元画像だけの周辺確率の分布表を作る
    p_i = p_i_j.sum(dim=1).view(k, 1).expand(k, k)
    # 同時確率の分布表から、元画像の10パターンをsumをして周辺化し、変換画像だけの周辺確率の分布表を作る
    p_j = p_i_j.sum(dim=0).view(1, k).expand(k, k)

    # 0に近い値をlogに入れると発散するので、避ける
    #p_i_j[(p_i_j < EPS).data] = EPS
    #p_j[(p_j < EPS).data] = EPS
    #p_i[(p_i < EPS).data] = EPS
    # 参考GitHubの実装（↑）は、PyTorchのバージョン1.3以上だとエラーになる
    # https://discuss.pytorch.org/t/pytorch-1-3-showing-an-error-perhaps-for-loss-computed-from-paired-outputs/68790/3

    # 0に近い値をlogに入れると発散するので、避ける
    p_i_j = torch.where(p_i_j < EPS, torch.tensor(
        [EPS], device=p_i_j.device), p_i_j)
    p_j = torch.where(p_j < EPS, torch.tensor([EPS], device=p_j.device), p_j)
    p_i = torch.where(p_i < EPS, torch.tensor([EPS], device=p_i.device), p_i)

    # 元画像、変換画像の同時確率と周辺確率から、相互情報量を計算
    # ただし、マイナスをかけて最小化問題にする

    """
    相互情報量を最大化したい
    ⇒結局、x_out, x_tf_outが持ちあう情報量が多くなって欲しい
    ⇒要は、x_out, x_tf_outが一緒になって欲しい

    p_i_jはx_out, x_tf_outの同時確率分布で、ミニバッチが極力、10×10のいろんなパターン、満遍なく一様が嬉しい

    前半の項、torch.log(p_i_j)はp_ijがどれも1に近いと大きな値（0に近い）になる。
    どれかが1であと0でバラついていないと、log0で小さな値（負の大きな値）になる
    つまり前半の項は、

    後半の項は、元画像、もしくは変換画像について、それぞれ周辺化して10通りのどれになるかを計算した項。
    周辺化した10×10のパターンを引き算して、前半の項が小さくなるのであれば、
    x_outとx_tf_outはあまり情報を共有していなかったことになる。
    """
    # https://qiita.com/Amanokawa/items/0aa24bc396dd88fb7d2a
    # を参考に、重みalphaを追加
    # 同時確率分布表のばらつきによる罰則を小さく ＝ 同時確率の分布がバラつきやすくする
    alpha = 2.0  # 論文や通常の相互情報量の計算はalphaは1です

    loss = -1*(p_i_j * (torch.log(p_i_j) - alpha *
                        torch.log(p_j) - alpha*torch.log(p_i))).sum()

    return loss



class TrainerConfig(BaseTrainerConfig):
    num_cluster:int = 10
    num_over_cluster:int = 100


class Trainer(BaseTrainer):
    # def metrics_acc(self, preds, gts):
    #     correct = torch.sum(torch.argmax(preds, dim=-1) == gts)
    #     return correct / len(preds)

    # def _visualize_confusion(self, ax, label, preds, gts):
    #     preds = torch.argmax(preds, dim=-1)
    #     cm = confusion_matrix(gts.numpy(), preds.numpy())
    #     sns.heatmap(cm, annot=True, ax=ax, fmt='g')
    #     ax.set_title(label)
    #     ax.set_xlabel('Predict', fontsize=13)
    #     ax.set_ylabel('GT', fontsize=13)

    # def visualize_train_confusion(self, ax, train_preds, train_gts, val_preds, val_gts):
    #     self._visualize_confusion(ax, 'train', train_preds, train_gts)

    # def visualize_val_confusion(self, ax, train_preds, train_gts, val_preds, val_gts):
    #     self._visualize_confusion(ax, 'val', val_preds, val_gts)

    def prepare(self):
        model = IICModel(
            input_size=1,
            num_cluster=self.config.num_cluster,
            num_over_cluster=self.config.num_over_cluster
        )
        self.criterion = nn.CrossEntropyLoss()
        return model

    def eval(self, inputs, gts):
        pairs = perturb_imagedata(inputs)

        data1, data1_over = self.model(inputs.to(self.device))
        data2, data2_over = self.model(pairs.to(self.device))

        loss = iid_loss(data1, data2)
        loss_over = iid_loss(data1_over, data2_over)

        total_loss = loss + loss_over

        return loss, None


class CLI(BaseMLCLI):
    class TrainArgs(BaseMLCLI.CommonArgs):
        lr:float = 0.001
        name: str = 'mnist'
        epoch: int = 20
        num_workers: int = 4
        batch_size: int = 32
        overwrite:bool = Field(False, cli=('--overwrite', '-O', ))

    def run_train(self, a:TrainArgs):
        dss = [datasets.MNIST(
            './datasets/MNIST',
            train = t,
            download = True,
            transform = transforms.Compose([
                transforms.ToTensor(),
            ])
        ) for t in [True, False] ]

        dss[0].data = dss[0].data[:10000, :, :]
        dss[1].data = dss[1].data[:1000, :, :]

        config = TrainerConfig(
            lr=a.lr,
            batch_size=a.batch_size,
            num_workers=a.num_workers,
        )

        t = Trainer(
            config=config,
            out_dir=f'out/models/{a.name}',
            train_dataset=dss[0],
            val_dataset=dss[1],
            overwrite=a.overwrite,
            fig_size=(20, 8),
            fig_col_count=2,
        )
        t.start(a.epoch)

if __name__ == '__main__':
    cli = CLI()
    cli.run()
