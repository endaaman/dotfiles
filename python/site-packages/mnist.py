import numpy as np
from sklearn.metrics import confusion_matrix
import seaborn as sns
import torch
from torch import nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from timm.scheduler import CosineLRScheduler

from endaaman.ml import BaseMLCLI, BaseDLArgs, BaseTrainer, BaseTrainerConfig, Field
from endaaman.metrics import BaseMetrics, AccuracyByChannel



class CNNModel(nn.Module):
    def __init__(self, input_size=1, output_size=10):
        super().__init__()
        self.output_size = output_size
        self.convs = nn.Sequential(
            nn.Conv2d(1, 32, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 32, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 16, 3, 1, 1),
            nn.ReLU(inplace=True),
        )
        self.pool = nn.AdaptiveAvgPool2d((4, 4))
        self.fc = nn.Linear(16 * 16, output_size)

    def forward(self, x, activate=False):
        x = self.convs(x)
        x = self.pool(x)
        x = torch.flatten(x, 1)
        x = self.fc(x)
        if activate:
            if self.output_size == 1:
                x = F.sigmoid(x)
            else:
                x = F.log_softmax(x, dim=1)
        return x

class TrainerConfig(BaseTrainerConfig):
    pass



class Trainer(BaseTrainer):
    def metrics_acc(self, preds, gts):
        correct = torch.sum(torch.argmax(preds, dim=-1) == gts)
        return correct / len(preds)

    def _visualize_confusion(self, ax, label, preds, gts):
        preds = torch.argmax(preds, dim=-1)
        cm = confusion_matrix(gts.numpy(), preds.numpy())
        sns.heatmap(cm, annot=True, ax=ax, fmt='g')
        ax.set_title(label)
        ax.set_xlabel('Predict', fontsize=13)
        ax.set_ylabel('GT', fontsize=13)

    def visualize_train_confusion(self, ax, train_preds, train_gts, val_preds, val_gts):
        self._visualize_confusion(ax, 'train', train_preds, train_gts)

    def visualize_val_confusion(self, ax, train_preds, train_gts, val_preds, val_gts):
        self._visualize_confusion(ax, 'val', val_preds, val_gts)

    def prepare(self):
        model = CNNModel(input_size=1, output_size=10)
        self.criterion = nn.CrossEntropyLoss()
        return model

    def eval(self, inputs, gts):
        preds = self.model(inputs.to(self.device))
        loss = self.criterion(preds, gts.to(self.device))
        return loss, preds.detach().cpu()

class CLI(BaseMLCLI):
    class TrainArgs(BaseMLCLI.CommonArgs):
        name: str = 'mnist'
        epoch: int = 20
        num_workers: int = 4
        batch_size: int = 32
        overwrite: bool = Field(False, cli=('--overwrite', ))

    def run_train(self, a:TrainArgs):
        dss = [datasets.MNIST(
            './datasets/MNIST',
            train = t,
            download = True,
            transform = transforms.Compose([
                transforms.ToTensor(),
            ])
        ) for t in [True, False] ]

        dss[0].data = dss[0].data[:10000, :, :]
        dss[1].data = dss[1].data[:1000, :, :]

        config = TrainerConfig(
            lr=0.001,
            batch_size=a.batch_size,
            num_workers=a.num_workers,
        )

        t = Trainer(
            config=config,
            out_dir=f'out/models/{a.name}',
            train_dataset=dss[0],
            val_dataset=dss[1],
            overwrite=a.overwrite,
            fig_size=(20, 8),
            fig_col_count=2,
        )
        t.start(a.epoch)

if __name__ == '__main__':
    cli = CLI()
    cli.run()
