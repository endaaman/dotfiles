import os
import itertools

import numpy as np
import pandas as pd
from tqdm import tqdm
from matplotlib import pyplot as plt
import cv2
import torch
from torch import nn
import torchvision
from torch.utils.data import Dataset
from torchvision.datasets import MNIST
from sklearn.metrics import confusion_matrix
import seaborn as sns
from pydantic import Field

from endaaman.ml import BaseMLArgs, BaseMLCLI, BaseTrainerConfig, BaseTrainer, Checkpoint
from endaaman.ml.metrics import ROCMetrics


J = os.path.join

PARAMS_COUNT = 256


def shuffle(t, dim=0):
    shape = t.size()
    idx = torch.randperm(t.shape[dim])
    return t[idx].view(shape)

class MILDataset(Dataset):
    def __init__(self,
                 train:bool,
                 batch_count:int,
                 target_labels:list,
                 bg_labels:list,
                 target_count:tuple[int, int],
                 ):
        self.batch_count = batch_count
        self.target_labels = target_labels
        self.bg_labels = bg_labels
        self.target_count = target_count

        ds = MNIST(root='datasets',
                   train=train,
                   download=True)
        self.data = ds.data

        bg_idxs = torch.where(torch.isin(ds.targets, torch.tensor(self.bg_labels)))[0]

        self.idxs = []
        self.labels = []
        for label in target_labels:
            if label < 0:
                count = int(len(ds.data) / 10 / self.target_count[0])
                for _ in range(count):
                    bg_idx = shuffle(torch.from_numpy(np.random.choice(bg_idxs, self.batch_count)))
                    self.idxs.append(bg_idx)
                    self.labels.append(label)
                print(label, len(self.idxs))
                continue

            base_idxs = torch.where(ds.targets == label)[0]
            counts = torch.randint(low=self.target_count[0], high=self.target_count[1], size=(len(base_idxs)//self.target_count[1], ))
            cursor = 0
            for count in counts:
                count = count.item()
                label_idx = base_idxs[cursor:cursor+count]
                cursor += count
                bg_count = self.batch_count - count
                bg_idx = torch.from_numpy(np.random.choice(bg_idxs, bg_count))
                assert bg_count == len(bg_idx)
                idx = torch.cat([label_idx, bg_idx])
                idx = shuffle(idx)
                self.idxs.append(idx)
                self.labels.append(label)
            print(label, len(self.idxs))

        self.idxs = torch.stack(self.idxs)
        self.labels = torch.tensor(self.labels)

    def __len__(self):
        return len(self.idxs)

    def __getitem__(self, i):
        x = self.data[self.idxs[i]]
        label_index = self.target_labels.index(self.labels[i])
        x = (x / 255).float()
        return x, label_index



class MILModel(nn.Module):
    def __init__(self, activation='softmax', params_count=PARAMS_COUNT, num_classes=1):
        super().__init__()
        self.activation = activation
        self.params_count = params_count
        self.num_classes = num_classes

        self.convs = nn.Sequential(
            nn.Conv2d(1, 32, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 32, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 16, 3, 1, 1),
            nn.ReLU(inplace=True),
        )
        self.pool = nn.AdaptiveAvgPool2d((4, 4))
        self.num_features = 16 * 16
        self.fc = nn.Linear(self.num_features, self.num_classes)

        self.u = nn.Linear(self.num_features, self.params_count, bias=False)
        self.v = nn.Linear(self.num_features, self.params_count, bias=False)
        self.w = nn.Linear(self.params_count, 1, bias=False)

    def compute_attention_scores(self, x):
        xu = torch.tanh(self.u(x))
        xv = torch.sigmoid(self.v(x))
        alpha = self.w(xu * xv)
        return alpha

    def compute_attentions(self, features):
        aa = []
        for feature in features:
            aa.append(self.compute_attention_scores(feature))
        aa = torch.stack(aa).flatten()
        if self.activation == 'softmax':
            aa = torch.softmax(aa, dim=-1)
        elif self.activation == 'sigmoid':
            aa = torch.sigmoid(aa)
        elif self.activation == 'raw':
            pass
        else:
            raise RuntimeError('Invalid activation:', self.activation)
        return aa

    def forward(self, x, activate=False, with_attentions=False):
        x = self.convs(x)
        x = self.pool(x)
        features = torch.flatten(x, 1)

        aa = self.compute_attentions(features)
        feature = (features * aa[:, None]).sum(dim=0)
        y = self.fc(feature)

        if activate:
            if self.num_classes > 1:
                y = torch.softmax(y, dim=-1)
            else:
                y = torch.sigmoid(y)

        if with_attentions:
            return y, aa.detach()
        return y


class CrossMILModel(nn.Module):
    def __init__(self, activation='softmax', params_count=256, num_classes=1):
        super().__init__()
        self.activation = activation
        self.params_count = params_count
        self.num_classes = num_classes

        self.convs = nn.Sequential(
            nn.Conv2d(1, 32, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 32, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 16, 3, 1, 1),
            nn.ReLU(inplace=True),
        )
        self.pool = nn.AdaptiveAvgPool2d((4, 4))
        self.num_features = 16 * 16
        self.fc = nn.Linear(self.num_features, self.num_classes)

        self.mse_u = nn.Linear(self.num_features, self.params_count, bias=False)
        # self.mse_v = nn.Linear(self.num_features, self.params_count, bias=False)
        self.mse_ub = nn.Parameter(torch.Tensor(np.zeros(self.params_count)))
        # self.mse_vb = nn.Parameter(torch.Tensor(np.zeros(self.params_count)))

        self.feature_u = nn.Linear(self.num_features, self.params_count)
        # self.feature_v = nn.Linear(self.num_features, self.params_count)

        self.u = nn.Linear(self.params_count*2, self.params_count*2)
        self.v = nn.Linear(self.params_count*2, self.params_count*2)
        self.w = nn.Linear(self.params_count*2, 1)

    def compute_attentions(self, features):
        batch_size = features.shape[0]
        aa = []

        idxs = torch.arange(batch_size)
        uv = torch.stack(torch.meshgrid(idxs, idxs, indexing='ij'), dim=-1)
        mesh = features[uv]

        mse = (mesh[:, :, 0, :] - mesh[:, :, 1, :]) ** 2

        mse_u = self.mse_u(mse)
        mse_u = torch.sum(mse_u, dim=1)
        mse_u = mse_u + self.mse_ub

        # mse_v = self.mse_v(mse)
        # mse_v = torch.sum(mse_v, dim=1)
        # mse_v = mse_v + self.mse_vb

        feature_u = self.feature_u(features)
        # feature_v = self.feature_v(features)

        integrated = torch.cat([mse_u, feature_u], dim=1)
        # v = torch.cat([mse_v, feature_v], dim=1)
        # v = torch.sigmoid(v)

        u = self.u(integrated)
        v = torch.sigmoid(self.v(integrated))
        aa = self.w(u * v)


        # aa = self.integrated_linear(u)

        # aa = self.integrated_linear(integrated)

        # aa = torch.stack(aa).flatten()
        if self.activation == 'softmax':
            aa = torch.softmax(aa, dim=-1)
        elif self.activation == 'sigmoid':
            aa = torch.sigmoid(aa)
        elif self.activation == 'raw':
            pass
        else:
            raise RuntimeError('Invalid activation:', self.activation)
        return aa

    def forward(self, xx, activate=False, with_attentions=False):
        xx = self.convs(xx)
        xx = self.pool(xx)
        xx = torch.flatten(xx, 1)

        aa = self.compute_attentions(xx)

        # print(aa.shape)
        # print(xx.shape)
        x = (xx * aa).sum(dim=0)
        y =  self.fc(x)

        # y = self.fc(features)
        # y = (logits * aa.view(-1, self.num_classes)).sum(dim=0)

        if activate:
            if self.num_classes > 1:
                y = torch.softmax(y, dim=-1)
            else:
                y = torch.sigmoid(y)

        if with_attentions:
            return y, aa.detach()
        return y



def select_model_class(name):
    return {
        'mil': MILModel,
        'cross': CrossMILModel,
    }[name]

class TrainerConfig(BaseTrainerConfig):
    model_name: str = 'mil'
    batch_size: int = 1
    activation: str
    target_labels: list
    bg_labels: list
    target_count: list

class Trainer(BaseTrainer):
    def metrics_acc(self, preds, gts):
        correct = torch.sum(torch.argmax(preds, dim=-1) == gts)
        return correct / len(preds)

    def _visualize_confusion(self, ax, label, preds, gts):
        preds = torch.argmax(preds, dim=-1)
        cm = confusion_matrix(gts.numpy(), preds.numpy())
        sns.heatmap(cm, annot=True, ax=ax, fmt='g')
        ax.set_title(label)
        ax.set_xlabel('Predict', fontsize=13)
        ax.set_ylabel('GT', fontsize=13)

    def visualize_train_confusion(self, ax, train_preds, train_gts, val_preds, val_gts):
        self._visualize_confusion(ax, 'train', train_preds, train_gts)

    def visualize_val_confusion(self, ax, train_preds, train_gts, val_preds, val_gts):
        self._visualize_confusion(ax, 'val', val_preds, val_gts)

    def prepare(self):
        C = select_model_class(self.config.model_name)

        model = C(
            num_classes=len(self.config.target_labels),
            activation=self.config.activation,
        )
        self.criterion = nn.CrossEntropyLoss()
        return model

    def eval(self, inputs, gts):
        inputs = inputs[0][:, None, ...]
        gt = gts
        pred = self.model(inputs.to(self.device), activate=False)
        pred = pred[None, ...]
        loss = self.criterion(pred, gt.to(self.device))
        return loss, pred.detach().cpu()


    # def get_metrics(self):
    #     keys=['auc', 'acc', 'recall', 'specificity']
    #     return {
    #         # 'acc': AccMetrics(),
    #         '_'.join(keys): ROCMetrics(keys=keys),
    #     }


BATCH_COUNT = 16
TARGET_LABELS=(0, 1, 2, -1)
BG_LABELS=(3, 4, 5, 6, 7, 8, 9, )
TARGET_COUNT = (1, 4)

class CLI(BaseMLCLI):
    class CommonArgs(BaseMLCLI.CommonArgs):
        pass

    class SampleArgs(BaseMLCLI.CommonArgs):
        index:int = Field(0, cli=('--index', '-i'))

    def run_sample(self, a):
        ds = MILDataset(
            train=True,
            batch_count=BATCH_COUNT,
            target_labels=TARGET_LABELS,
            bg_labels=BG_LABELS,
            target_count=TARGET_COUNT
        )
        self.ds = ds

        x, label_index = ds[a.index]
        # x, label_index = ds[len(ds)-1]
        plt.title(f'{ds.target_labels[label_index]} (idx:{label_index})')
        plt.imshow(torchvision.utils.make_grid(x[:, None, ...], nrow=3).permute(1,2,0))
        plt.show()

    def run_model(self, a):
        model = MILModel(num_classes=3)
        x = torch.randn(9, 1, 28, 28)
        y, aa = model(x, with_attentions=True, activate=True)
        print(y)
        print(aa)


    class TrainArgs(CommonArgs):
        model:str = 'mil'
        activation: str = 'softmax'
        epoch: int = 10

    def run_train(self, a):
        dss = [MILDataset(
            train=t,
            batch_count=BATCH_COUNT,
            target_labels=TARGET_LABELS,
            bg_labels=BG_LABELS,
            target_count=TARGET_COUNT
        ) for t in [True, False]]

        config = TrainerConfig(
            model_name=a.model,
            lr=0.001,
            activation=a.activation,
            target_labels=TARGET_LABELS,
            bg_labels=BG_LABELS,
            target_count=TARGET_COUNT,
        )

        trainer = Trainer(
            config=config,
            out_dir=f'out/mil2/{a.model}_{a.activation}',
            train_dataset=dss[0],
            val_dataset=dss[1],
        )

        trainer.start(a.epoch)


    class PredArgs(BaseMLCLI.CommonArgs):
        model_dir:str = Field(..., cli=('--model-dir', '-M'))
        label:int = 1
        label_count:int = Field(3, cli=('--label-count', ))
        total_count:int = Field(9, cli=('--total-count', ))
        noshow:bool = Field(False, cli=('--noshow', ))

    def run_pred(self, a:PredArgs):
        chp_path = J(a.model_dir, 'checkpoint_best.pt')
        c:Checkpoint = torch.load(chp_path)
        config = TrainerConfig.from_file(J(a.model_dir, 'config.json'))
        ds = MNIST(
            root='./datasets/MNIST',
            train=False,
            download=True,
        )
        C = select_model_class(config.model_name)
        model = C(
            activation=config.activation,
            num_classes=len(config.target_labels)
        )
        model.load_state_dict(c.model_state)

        bg_pool = ds.data[torch.isin(ds.targets, torch.tensor(config.bg_labels))]

        if a.label < 0:
            bgs = bg_pool[np.random.choice(bg_pool.shape[0], a.total_count)]
            x = shuffle(bgs)
        else:
            x_pool = ds.data[ds.targets == a.label]
            xx = x_pool[np.random.choice(x_pool.shape[0], a.label_count)]
            bgs = bg_pool[np.random.choice(x_pool.shape[0], a.total_count-a.label_count)]
            x = shuffle(torch.cat([xx, bgs]))

        x = x[:, None, ...] / 255
        print(x.shape)

        y, aa = model(x, activate=True, with_attentions=True)

        fig, axes = plt.subplots(2, 1, figsize=(a.total_count//2, 4), tight_layout=True, facecolor="whitesmoke")

        ax = axes[0]

        pred = ' '.join([f'{config.target_labels[i]}:{p:.2f}' for i, p in enumerate(y)])
        ax.set_title(f'pred: {pred}')
        print(pred)
        ax.imshow(cv2.hconcat(x.numpy().squeeze()))
        # plt.imshow(torchvision.utils.make_grid(x, nrow=3).permute(1,2,0))

        ax = axes[1]
        # plt.pcolor([aa.numpy()])
        print(aa[..., a.label])
        sns.heatmap([aa.numpy()[..., a.label]], annot=True, fmt='1.2f', ax=ax, cbar=False)

        plt.savefig(J(a.model_dir, f'{a.label}_{a.label_count}_{a.total_count}_{a.seed}.png'))
        if not a.noshow:
            plt.show()


    class RecallArgs(CommonArgs):
        model_dir:str = Field(..., cli=('--model-dir', '-M'))
        label:int = 1
        total_count:int = Field(9, cli=('--total-count', ))
        times:int = 1000

    def run_recall(self, a:RecallArgs):
        chp_path = J(a.model_dir, 'checkpoint_best.pt')
        c:Checkpoint = torch.load(chp_path)
        config = TrainerConfig.from_file(J(a.model_dir, 'config.json'))
        ds = MNIST(
            root='./datasets/MNIST',
            train=False,
            download=True,
        )
        model = MILModel(
            activation=config.activation,
            num_classes=len(config.target_labels)
        )
        model.load_state_dict(c.model_state)

        label_index = config.target_labels.index(a.label)

        bg_pool = ds.data[torch.isin(ds.targets, torch.tensor(config.bg_labels))]
        x_pool = ds.data[ds.targets == a.label]

        result = []

        t = tqdm(range(1, a.total_count//2))
        for count in t:
            correct = 0
            for _ in range(a.times):
                xx = x_pool[np.random.choice(x_pool.shape[0], count)]
                bgs = bg_pool[np.random.choice(x_pool.shape[0], a.total_count-count)]
                x = torch.cat([xx, bgs])
                x = x[:, None, ...]/255
                y = model(x, activate=True)
                pred = torch.argmax(y.flatten()).item()
                if pred == label_index:
                    correct += 1
            t.set_description(f'[{count}] {correct/a.times}')
            t.refresh()
            result.append({
                'count': count,
                'acc': correct/a.times,
            })
        print(result)

        df = pd.DataFrame(result)
        df.to_excel(J(a.model_dir, f'result_{a.label}_{a.total_count}.xlsx'))


    class PlotResultArgs(CommonArgs):
        label:int = 0

    def run_plot_result(self, a:CommonArgs):
        df_softmax = pd.read_excel(f'out/mil2/softmax_0/result_{a.label}_20.xlsx')
        df_sigmoid = pd.read_excel(f'out/mil2/sigmoid_0/result_{a.label}_20.xlsx')

        plt.title(a.label)
        plt.plot(df_softmax['count'], df_softmax['acc'], label='softmax')
        plt.plot(df_sigmoid['count'], df_sigmoid['acc'], label='sigmoid')
        plt.legend()
        plt.grid()
        plt.savefig(f'out/result_{a.label}.png')
        plt.show()

    def run_i(self, a):
        # SIZE = (3, 5)
        BATCH_SIZE = 3
        NUM_FEATURES = 4

        # features = torch.randn(BATCH_SIZE, NUM_FEATURES)
        features = torch.tensor([
            [0.0,1,2,3],
            [0,1,2,3],
            [1,2,3,4],
        ])

        # short = np.max(SIZE)
        # convs = []
        # combs = torch.tensor(list(itertools.combinations(range(BATCH_SIZE), 2)))
        # print(combs)
        # features_combs = features[combs]
        # u = features_combs[:, 0]
        # v = features_combs[:, 1]
        # mse = (u - v) ** 2 # [C, F]

        # for i, feature in enumerate(features):
        #     corrs = []
        #     for other in features:
        #         corr = (feature - other) ** 2
        #         corrs.append(corr)
        #     print(corrs)
        #     corrs = torch.mean(torch.stack(corrs), dim=0)
        #     print(i, feature.shape, corrs.shape)
        # print(corrs)

        # permutations
        idxs = torch.range(NUM_FEATURES)
        uv = torch.stack(torch.meshgrid(features, features, indexing='ij'), dim=-1)

        print(uv.shape)

    def run_m(self, a):
        m = MAMILModel()

        x = torch.randn(9, 1, 28, 28)

        print(m(x).shape)


    def run_a(self, a:CommonArgs):
        SIZE = (5, 4)
        NUM_FEATURES = 128

        features = torch.randn(1, SIZE[0], SIZE[1], NUM_FEATURES)
        short = np.min([features.shape[1], features.shape[2]])

        print('short', short)
        kernel_step = short//2*2+1
        print(kernel_step)
        MAX_KERNEL_SIZE = short
        MAX_KERNEL_SIZE = 5

        p = nn.Parameter()

        convs = []
        for base in range(0, MAX_KERNEL_SIZE//2+1):
            print(base, base*2+1)
            conv = nn.Conv2d(
                in_channels=NUM_FEATURES,
                out_channels=1,
                kernel_size=base*2+1,
                padding=base,
                padding_mode='circular',
            )
            convs.append(conv)

        # compute_attentions

        # B, H, W, C -> B, C, H, W
        features = features.permute(0, 3, 1, 2)
        stacked_features = []
        for conv in convs:
            f = conv(features)
            stacked_features.append(f)
            print(f.shape)

        features = torch.concat(stacked_features, dim=1)

        print(features.shape)


    def run_mesh(self, a):
        xx = np.arange(-10, 10, 0.1)
        yy = np.arange(-10, 10, 0.1)

        X, Y = np.meshgrid(xx, yy)
        Z = np.exp(-(X - Y) ** 2)

        fig = plt.figure(figsize = (8, 8))
        ax = fig.add_subplot(111, projection="3d")
        ax.set_xlabel("x")
        ax.set_ylabel("y")
        ax.set_zlabel("z")
        # ax.plot_surface(X, Y, Z, cmap = "summer")
        ax.scatter(X, Y, Z, cmap = "summer")
        plt.show()


if __name__ == '__main__':
    cli = CLI()
    cli.run()
