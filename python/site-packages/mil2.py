import numpy as np
from matplotlib import pyplot as plt

import torch
from torch import nn
import torchvision
from torch.utils.data import Dataset
from torchvision.datasets import MNIST
from sklearn.metrics import confusion_matrix
import seaborn as sns

from endaaman.ml import BaseMLArgs, BaseMLCLI, BaseTrainerConfig, BaseTrainer
from endaaman.ml.metrics import ROCMetrics


def shuffle(t, dim=0):
    shape = t.size()
    idx = torch.randperm(t.shape[dim])
    return t[idx].view(shape)

class MILDataset(Dataset):
    def __init__(self, train, limit=-1,
                 target_labels=[0, 1, 2, 3],
                 bg_labels=[0],
                 tile_size=9,
                 count=(4, 8),
                 ):
        self.tile_size = tile_size
        self.target_labels = target_labels
        self.count = count
        ds = MNIST(root='datasets',
                   train=train,
                   download=True)
        self.data = ds.data
        # self.labels = ds.targets

        self.xxx = []
        self.bgs = []

        for label in range(10):
            if label in target_labels:
                self.xxx.append(shuffle(self.data[ds.targets == label]))
                continue
            if label in bg_labels:
                self.bgs.append(self.data[ds.targets == label])
                continue
        self.bgs = shuffle(torch.cat(self.bgs))

        MIN_COUNT = self.count[0]
        MAX_COUNT = self.count[1]

        self.idxs = []
        self.counts_by_label = []

        for label_index, xx in enumerate(self.xxx):
            S = 0
            idx = []
            counts = torch.randint(low=MIN_COUNT, high=MAX_COUNT, size=(len(xx)//MIN_COUNT, ))
            i = 0
            while S+counts[i] < len(xx):
                idx.append(torch.arange(counts[i]) + S)
                S += counts[i]
                i += 1
            self.idxs.append(idx)
            self.counts_by_label.append(len(idx))

    def get_label_by_global_idx(self, global_idx):
        S = 0
        for label_index, T in enumerate(self.counts_by_label):
            if global_idx < S+T:
                return label_index, self.idxs[label_index][global_idx-S]
            S += T
        raise RuntimeError(f'{global_idx} maybe out of range ({T})')

    def __len__(self):
        # print('sum', sum(self.counts_by_label))
        return sum(self.counts_by_label)

    def __getitem__(self, global_idx):
        label_index, idx = self.get_label_by_global_idx(global_idx)
        xx = self.xxx[label_index][idx]
        bg_count = self.tile_size - len(idx)
        bg_idx = np.random.choice(len(self.bgs), bg_count)
        bgs = self.bgs[bg_idx]
        x = shuffle(torch.cat([xx, bgs]))
        x = (x / 255).float()
        return x, label_index



class MILModel(nn.Module):
    def __init__(self, activation='softmax', params_count=64, num_classes=1):
        super().__init__()
        self.activation = activation
        self.params_count = params_count
        self.num_classes = num_classes

        self.convs = nn.Sequential(
            nn.Conv2d(1, 32, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 32, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 16, 3, 1, 1),
            nn.ReLU(inplace=True),
        )
        self.pool = nn.AdaptiveAvgPool2d((4, 4))
        self.num_features = 16 * 16
        self.fc = nn.Linear(self.num_features, self.num_classes)

        self.u = nn.Linear(self.num_features, self.params_count, bias=False)
        self.v = nn.Linear(self.num_features, self.params_count, bias=False)
        self.w = nn.Linear(self.params_count, 1, bias=False)


    def compute_attention_scores(self, x):
        xu = torch.tanh(self.u(x))
        xv = torch.sigmoid(self.v(x))
        alpha = self.w(xu * xv)
        return alpha

    def compute_attentions(self, features):
        aa = []
        for feature in features:
            aa.append(self.compute_attention_scores(feature))
        aa = torch.stack(aa).flatten()
        if self.activation == 'softmax':
            aa = torch.softmax(aa, dim=0)
        elif self.activation == 'sigmoid':
            aa = torch.sigmoid(aa)
        else:
            raise RuntimeError('Invalid activation:', activate)
        return aa

    def forward(self, x, activate=False, with_attentions=False):
        x = self.convs(x)
        x = self.pool(x)
        features = torch.flatten(x, 1)

        aa = self.compute_attentions(features)
        feature = (features * aa[:, None]).sum(dim=0)
        y = self.fc(feature)

        if activate:
            if self.num_classes > 1:
                y = torch.softmax(y, dim=-1)
            else:
                y = torch.sigmoid(y)

        if with_attentions:
            return y, aa.detach()
        return y



class TrainerConfig(BaseTrainerConfig):
    batch_size: int = 1
    activation: str
    count: list
    target_labels: list
    bg_labels: list

class Trainer(BaseTrainer):
    def metrics_acc(self, preds, gts):
        correct = torch.sum(torch.argmax(preds, dim=-1) == gts)
        return correct / len(preds)

    def _visualize_confusion(self, ax, label, preds, gts):
        preds = torch.argmax(preds, dim=-1)
        cm = confusion_matrix(gts.numpy(), preds.numpy())
        sns.heatmap(cm, annot=True, ax=ax, fmt='g')
        ax.set_title(label)
        ax.set_xlabel('Predict', fontsize=13)
        ax.set_ylabel('GT', fontsize=13)

    def visualize_train_confusion(self, ax, train_preds, train_gts, val_preds, val_gts):
        self._visualize_confusion(ax, 'train', train_preds, train_gts)

    def visualize_val_confusion(self, ax, train_preds, train_gts, val_preds, val_gts):
        self._visualize_confusion(ax, 'val', val_preds, val_gts)

    def prepare(self):
        model = MILModel(
            num_classes=len(self.config.target_labels),
            activation=self.config.activation,
        )
        self.criterion = nn.CrossEntropyLoss()
        return model

    def eval(self, inputs, gts):
        inputs = inputs[0][:, None, ...]
        gt = gts
        pred = self.model(inputs.to(self.device), activate=False)
        pred = pred[None, ...]
        loss = self.criterion(pred, gt.to(self.device))
        return loss, pred.detach().cpu()


    # def get_metrics(self):
    #     keys=['auc', 'acc', 'recall', 'specificity']
    #     return {
    #         # 'acc': AccMetrics(),
    #         '_'.join(keys): ROCMetrics(keys=keys),
    #     }


TARGET_LABELS = [1, 2, 3]
BG_LABELS = [0, 9, 8, 7, 6, 5, 4, ]
TILE_SIZE = 9
COUNT = (1, 3)

class CLI(BaseMLCLI):
    class CommonArgs(BaseMLCLI.CommonArgs):
        pass

    def run_sample(self, a):
        ds = MILDataset(
            train=True,
            target_labels=TARGET_LABELS,
            bg_labels=BG_LABELS,
            tile_size=TILE_SIZE,
            count=COUNT
        )

        i = 0
        while i < len(ds):
            x, label_index = ds[i]
            i += 1
        # x, label_index = ds[len(ds)-1]
        plt.title(f'{ds.target_labels[label_index]} (idx:{label_index})')
        plt.imshow(torchvision.utils.make_grid(x[:, None, ...], nrow=3).permute(1,2,0))
        plt.show()

    def run_model(self, a):
        model = MILModel(num_classes=3)
        x = torch.randn(9, 1, 28, 28)
        y, aa = model(x, with_attentions=True, activate=True)
        print(y)
        print(aa)


    class TrainArgs(CommonArgs):
        activation: str = 'softmax'
        epoch: int = 30

    def run_train(self, a):
        dss = [MILDataset(
            train=t,
            target_labels=TARGET_LABELS,
            bg_labels=BG_LABELS,
            tile_size=TILE_SIZE,
            count=COUNT
        ) for t in [True, False]]

        config = TrainerConfig(
            lr=0.001,
            activation=a.activation,
            count=COUNT,
            target_labels=TARGET_LABELS,
            bg_labels=BG_LABELS,
        )

        trainer = Trainer(
            config=config,
            out_dir=f'out/mil2/{a.activation}',
            train_dataset=dss[0],
            val_dataset=dss[1],
        )

        trainer.start(a.epoch)


if __name__ == '__main__':
    cli = CLI()
    cli.run()

