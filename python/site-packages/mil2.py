import os
import numpy as np
from matplotlib import pyplot as plt

import cv2
import torch
from torch import nn
import torchvision
from torch.utils.data import Dataset
from torchvision.datasets import MNIST
from sklearn.metrics import confusion_matrix
import seaborn as sns
from pydantic import Field

from endaaman.ml import BaseMLArgs, BaseMLCLI, BaseTrainerConfig, BaseTrainer, Checkpoint
from endaaman.ml.metrics import ROCMetrics


J = os.path.join


def shuffle(t, dim=0):
    shape = t.size()
    idx = torch.randperm(t.shape[dim])
    return t[idx].view(shape)

class MILDataset(Dataset):
    def __init__(self,
                 train:bool,
                 batch_count:int,
                 target_labels:list,
                 bg_labels:list,
                 target_count:tuple[int, int],
                 ):
        self.batch_count = batch_count
        self.target_labels = target_labels
        self.bg_labels = bg_labels
        self.target_count = target_count

        ds = MNIST(root='datasets',
                   train=train,
                   download=True)
        self.data = ds.data

        bg_idxs = torch.where(torch.isin(ds.targets, torch.tensor(self.bg_labels)))[0]

        self.idxs = []
        self.labels = []
        for label in target_labels:
            if label < 0:
                count = int(len(ds.data) / 10 / self.target_count[0])
                for _ in range(count):
                    bg_idx = shuffle(torch.from_numpy(np.random.choice(bg_idxs, self.batch_count)))
                    self.idxs.append(bg_idx)
                    self.labels.append(label)
                print(label, len(self.idxs))
                continue

            base_idxs = torch.where(ds.targets == label)[0]
            counts = torch.randint(low=self.target_count[0], high=self.target_count[1], size=(len(base_idxs)//self.target_count[1], ))
            cursor = 0
            for count in counts:
                count = count.item()
                label_idx = base_idxs[cursor:cursor+count]
                cursor += count
                bg_count = self.batch_count - count
                bg_idx = torch.from_numpy(np.random.choice(bg_idxs, bg_count))
                assert bg_count == len(bg_idx)
                idx = torch.cat([label_idx, bg_idx])
                idx = shuffle(idx)
                self.idxs.append(idx)
                self.labels.append(label)
            print(label, len(self.idxs))

        self.idxs = torch.stack(self.idxs)
        self.labels = torch.tensor(self.labels)

    def __len__(self):
        return len(self.idxs)

    def __getitem__(self, i):
        x = self.data[self.idxs[i]]
        label_index = self.target_labels.index(self.labels[i])
        x = (x / 255).float()
        return x, label_index



class MILModel(nn.Module):
    def __init__(self, activation='softmax', params_count=64, num_classes=1):
        super().__init__()
        self.activation = activation
        self.params_count = params_count
        self.num_classes = num_classes

        self.convs = nn.Sequential(
            nn.Conv2d(1, 32, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 32, 3, 1, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 16, 3, 1, 1),
            nn.ReLU(inplace=True),
        )
        self.pool = nn.AdaptiveAvgPool2d((4, 4))
        self.num_features = 16 * 16
        self.fc = nn.Linear(self.num_features, self.num_classes)

        self.u = nn.Linear(self.num_features, self.params_count, bias=False)
        self.v = nn.Linear(self.num_features, self.params_count, bias=False)
        self.w = nn.Linear(self.params_count, 1, bias=False)


    def compute_attention_scores(self, x):
        xu = torch.tanh(self.u(x))
        xv = torch.sigmoid(self.v(x))
        alpha = self.w(xu * xv)
        return alpha

    def compute_attentions(self, features):
        aa = []
        for feature in features:
            aa.append(self.compute_attention_scores(feature))
        aa = torch.stack(aa).flatten()
        if self.activation == 'softmax':
            aa = torch.softmax(aa, dim=-1)
        elif self.activation == 'sigmoid':
            aa = torch.sigmoid(aa)
        else:
            raise RuntimeError('Invalid activation:', self.activation)
        return aa

    def forward(self, x, activate=False, with_attentions=False):
        x = self.convs(x)
        x = self.pool(x)
        features = torch.flatten(x, 1)

        aa = self.compute_attentions(features)
        feature = (features * aa[:, None]).sum(dim=0)
        y = self.fc(feature)

        if activate:
            if self.num_classes > 1:
                y = torch.softmax(y, dim=-1)
            else:
                y = torch.sigmoid(y)

        if with_attentions:
            return y, aa.detach()
        return y



class TrainerConfig(BaseTrainerConfig):
    batch_size: int = 1
    activation: str
    target_labels: list
    bg_labels: list
    target_count: list

class Trainer(BaseTrainer):
    def metrics_acc(self, preds, gts):
        correct = torch.sum(torch.argmax(preds, dim=-1) == gts)
        return correct / len(preds)

    def _visualize_confusion(self, ax, label, preds, gts):
        preds = torch.argmax(preds, dim=-1)
        cm = confusion_matrix(gts.numpy(), preds.numpy())
        sns.heatmap(cm, annot=True, ax=ax, fmt='g')
        ax.set_title(label)
        ax.set_xlabel('Predict', fontsize=13)
        ax.set_ylabel('GT', fontsize=13)

    def visualize_train_confusion(self, ax, train_preds, train_gts, val_preds, val_gts):
        self._visualize_confusion(ax, 'train', train_preds, train_gts)

    def visualize_val_confusion(self, ax, train_preds, train_gts, val_preds, val_gts):
        self._visualize_confusion(ax, 'val', val_preds, val_gts)

    def prepare(self):
        model = MILModel(
            num_classes=len(self.config.target_labels),
            activation=self.config.activation,
        )
        self.criterion = nn.CrossEntropyLoss()
        return model

    def eval(self, inputs, gts):
        inputs = inputs[0][:, None, ...]
        gt = gts
        pred = self.model(inputs.to(self.device), activate=False)
        pred = pred[None, ...]
        loss = self.criterion(pred, gt.to(self.device))
        return loss, pred.detach().cpu()


    # def get_metrics(self):
    #     keys=['auc', 'acc', 'recall', 'specificity']
    #     return {
    #         # 'acc': AccMetrics(),
    #         '_'.join(keys): ROCMetrics(keys=keys),
    #     }


BATCH_COUNT = 16
TARGET_LABELS=(0, 1, 2, -1)
BG_LABELS=(3, 4, 5, 6, 7, 8, 9, )
TARGET_COUNT = (4, 8)

class CLI(BaseMLCLI):
    class CommonArgs(BaseMLCLI.CommonArgs):
        pass

    class SampleArgs(BaseMLCLI.CommonArgs):
        index:int = Field(0, cli=('--index', '-i'))

    def run_sample(self, a):
        ds = MILDataset(
            train=True,
            batch_count=BATCH_COUNT,
            target_labels=TARGET_LABELS,
            bg_labels=BG_LABELS,
            target_count=TARGET_COUNT
        )
        self.ds = ds

        x, label_index = ds[a.index]
        # x, label_index = ds[len(ds)-1]
        plt.title(f'{ds.target_labels[label_index]} (idx:{label_index})')
        plt.imshow(torchvision.utils.make_grid(x[:, None, ...], nrow=3).permute(1,2,0))
        plt.show()

    def run_model(self, a):
        model = MILModel(num_classes=3)
        x = torch.randn(9, 1, 28, 28)
        y, aa = model(x, with_attentions=True, activate=True)
        print(y)
        print(aa)


    class TrainArgs(CommonArgs):
        activation: str = 'softmax'
        epoch: int = 10

    def run_train(self, a):
        dss = [MILDataset(
            train=t,
            batch_count=BATCH_COUNT,
            target_labels=TARGET_LABELS,
            bg_labels=BG_LABELS,
            target_count=TARGET_COUNT
        ) for t in [True, False]]

        config = TrainerConfig(
            lr=0.001,
            activation=a.activation,
            target_labels=TARGET_LABELS,
            bg_labels=BG_LABELS,
            target_count=TARGET_COUNT,
        )

        trainer = Trainer(
            config=config,
            out_dir=f'out/mil2/{a.activation}',
            train_dataset=dss[0],
            val_dataset=dss[1],
        )

        trainer.start(a.epoch)


    class PredArgs(BaseMLCLI.CommonArgs):
        model_dir:str = Field(..., cli=('--model-dir', '-M'))
        label:int = 1
        label_count:int = Field(3, cli=('--label-count', ))
        total_count:int = Field(9, cli=('--total-count', ))

    def run_pred(self, a:PredArgs):
        chp_path = J(a.model_dir, 'checkpoint_best.pt')
        c:Checkpoint = torch.load(chp_path)
        config = TrainerConfig.from_file(J(a.model_dir, 'config.json'))
        ds = MNIST(
            root='./datasets/MNIST',
            train=False,
            download=True,
        )
        model = MILModel(
            activation=config.activation,
            num_classes=len(config.target_labels)
        )
        model.load_state_dict(c.model_state)

        bg_pool = ds.data[torch.isin(ds.targets, torch.tensor(config.bg_labels))]

        if a.label < 0:
            bgs = bg_pool[np.random.choice(bg_pool.shape[0], a.total_count)]
            x = shuffle(bgs)
        else:
            x_pool = ds.data[ds.targets == a.label]
            xx = x_pool[np.random.choice(x_pool.shape[0], a.label_count)]
            bgs = bg_pool[np.random.choice(x_pool.shape[0], a.total_count-a.label_count)]
            x = shuffle(torch.cat([xx, bgs]))

        x = x[:, None, ...] / 255
        print(x.shape)

        y, aa = model(x, activate=True, with_attentions=True)

        fig, axes = plt.subplots(2, 1, figsize=(a.total_count//2, 5), tight_layout=True, facecolor="whitesmoke")

        ax = axes[0]

        pred = ' '.join([f'{config.target_labels[i]}:{p:.2f}' for i, p in enumerate(y)])
        ax.set_title(f'pred: {pred}')
        ax.imshow(cv2.hconcat(x.numpy().squeeze()))
        # plt.imshow(torchvision.utils.make_grid(x, nrow=3).permute(1,2,0))

        ax = axes[1]
        # plt.pcolor([aa.numpy()])
        sns.heatmap([aa.numpy()], annot=True, fmt='1.2f', ax=ax, cbar=False)

        plt.savefig(J(a.model_dir, f'{a.label}_{a.label_count}_{a.total_count}.png'))
        plt.show()



if __name__ == '__main__':
    cli = CLI()
    cli.run()
