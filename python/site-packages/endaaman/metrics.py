import torch
import numpy as np
from sklearn import metrics
from .functional import multi_accuracy


class BaseMetrics:
    def __init__(self, format='{:.3f}', threshold=0.5, selector=None):
        self.format = format
        self.threshold = threshold
        self.selector = selector or (lambda *aa: [*aa])

    def __call__(self, preds, gts):
        preds, gts = self.selector(preds, gts)
        vv = self.calc(preds, gts)
        if vv is None:
            return None
        if not isinstance(vv, (tuple, list)):
            vv = (vv, )
        values = []
        for v in vv:
            if torch.is_tensor(v):
                if len(v.shape) > 0:
                    raise RuntimeError('Value should be single:', v)
                v = v.item()
            values.append(v)
        return values

    def calc(self, preds, gts):
        raise RuntimeError('Not implemented')


class BinaryAccuracy(BaseMetrics):
    def calc(self, preds, gts):
        pred_y = preds.flatten() > self.threshold
        gts_y = gts.flatten() > self.threshold
        correct = torch.sum(gts_y == pred_y)
        return correct / len(gts_y)

class BinaryRecall(BaseMetrics):
    def calc(self, preds, gts):
        pred_y = preds.flatten() > self.threshold
        gts_y = gts.flatten() > self.threshold
        pos_gts_y = gts_y(gts_y > 0)
        if len(pos_gts_y) == 0:
            return -0.0
        return torch.sum(pred_y[gts_y > 0] == pos_gts_y) / len(pos_gts_y)

class BinarySpecificity(BaseMetrics):
    def calc(self, preds, gts):
        pred_y = preds.flatten() > self.threshold
        gts_y = gts.flatten() > self.threshold
        neg_gts_y = gts_y[gts_y < 1]
        if len(neg_gts_y) == 0:
            return -0.0
        return torch.sum(pred_y[gts_y < 1] == neg_gts_y) / len(neg_gts_y)

class BinaryAUC(BaseMetrics):
    def calc(self, preds, gts):
        pred_y = preds.flatten().numpy()
        gts_y = gts.flatten().numpy()
        return metrics.roc_auc_score(gts_y, pred_y)

class MultiAccuracy(BaseMetrics):
    def __init__(self, by_index=True, **kwargs):
        super().__init__(**kwargs)
        self.by_index = by_index

    def calc(self, preds, gts):
        return multi_accuracy(preds, gts, self.by_index)

class MultiMacroAccuracy(BaseMetrics):
    def __init__(self, by_index=True, **kwargs):
        super().__init__(**kwargs)
        self.by_index = by_index

    def calc(self, preds, gts):
        pass

class AccuracyByChannel(BaseMetrics):
    def __init__(self, target_channel, by_index=True, **kwargs):
        super().__init__(**kwargs)
        self.target_channel = target_channel
        self.by_index = by_index

    def calc(self, preds, gts):
        target_idx = gts == self.target_channel
        preds = preds[target_idx]
        gts = gts[target_idx]
        if len(gts) == 0:
            return 0.0
        preds_label = np.argmax(preds, axis=1)
        if self.by_index:
            gts_label = gts
        else:
            gts_label = torch.argmax(gts, axis=1)
        correct = torch.sum(gts_label == preds_label)

        return correct / len(gts_label)
