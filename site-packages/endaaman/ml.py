import os
import re
import math
import random
from pathlib import Path
import subprocess
from typing import TypeVar
from functools import lru_cache

import torch
import numpy as np
import matplotlib
from matplotlib import ticker, pyplot as plt
from tqdm import tqdm
from pydantic import BaseModel, Field
from torch import optim
from torch.optim.lr_scheduler import LambdaLR
from torch.utils.data import DataLoader
import torch.multiprocessing
from torchvision import transforms

# from .predictor import BasePredictor
from .trainer import BaseTrainer, BaseTrainerConfig, Checkpoint
from .cli import BaseCLI
# pylint: disable=unused-wildcard-import,wildcard-import
from .ml_utils import *


torch.multiprocessing.set_sharing_strategy('file_system')



class BaseMLArgs(BaseModel):
    seed: int = Field(get_global_seed(), cli=('--seed', ))

class BaseDLArgs(BaseMLArgs):
    cpu: bool = Field(False, cli=('--cpu', ))
    batch_size: int = Field(8, cli=('--batch-size', '-B'))
    num_workers: int = Field(4, cli=('--num_workers', '-N'))
    epoch: int = Field(50, cli=('--epoch', '-E'))

class BaseMLCLI(BaseCLI):
    class CommonArgs(BaseMLArgs):
        pass

    def _pre_common(self, a:BaseMLArgs):
        fix_global_seed(self.a.seed)
        super()._pre_common(a)
