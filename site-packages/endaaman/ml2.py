import os
import re
import math
import random
from pathlib import Path
import subprocess
from typing import TypeVar
from functools import lru_cache

import torch
import numpy as np
import matplotlib
from matplotlib import ticker, pyplot as plt
from tqdm import tqdm
from pydantic import BaseModel, Field
from torch import optim
from torch.optim.lr_scheduler import LambdaLR
from torch.utils.data import DataLoader
import torch.multiprocessing
from torchvision import transforms

from .trainer import Trainer, Checkpoint
from .predictor import Predictor
from .cli import BaseCLI
from .ml_utils import fix_global_seed, get_global_seed, pil_to_tensor, tensor_to_pil


torch.multiprocessing.set_sharing_strategy('file_system')



class BaseMLArgs(BaseModel):
    seed: int = Field(get_global_seed(), cli=('--seed', ))

class BaseDLArgs(BaseMLArgs):
    cpu: bool = Field(False, cli=('--cpu', ))
    batch_size: int = Field(8, cli=('--batch-size', '-B'))
    num_workers: int = Field(4, cli=('--num_workers', '-N'))
    epoch: int = Field(50, cli=('--epoch', '-E'))

class BaseMLCLI(BaseCLI):
    def _pre_common(self, a:BaseMLArgs):
        fix_global_seed(self.a.seed)
        super()._pre_common(a)
