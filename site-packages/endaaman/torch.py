import os
import re
import math
import random
from pathlib import Path
import subprocess

import torch
import numpy as np
import matplotlib
from matplotlib import ticker, pyplot as plt
from torch import optim
from torch.optim.lr_scheduler import LambdaLR
from torch.utils.data import DataLoader
from torchvision import transforms
from tqdm import tqdm

from .torch_utils import get_random_states, restore_random_states, pil_to_tensor, tensor_to_pil
from .commander import Commander
from .trainer import Trainer, Checkpoint
from .predictor import Predictor


__GLOBAL_SEED = 42

def get_global_seed():
    return __GLOBAL_SEED

def set_global_seed(seed):
    global __GLOBAL_SEED
    __GLOBAL_SEED = seed

class MLCommander(Commander):
    def with_suffix(self, s):
        if self.a.suffix:
            return f'{s}_{self.a.suffix}'
        return s

    def _arg_common(self, parser):
        self._common_parser.add_argument('--seed', type=int, default=self.defaults.get('seed', get_global_seed()))
        self._common_parser.add_argument('--suffix', default='')
        super()._arg_common(parser)

    def _pre_common(self):
        random.seed(self.a.seed)
        np.random.seed(self.a.seed)
        torch.manual_seed(self.a.seed)
        torch.random.manual_seed(self.a.seed)
        torch.cuda.manual_seed(self.a.seed)
        torch.backends.cudnn.deterministic = True
        torch.use_deterministic_algorithms = True
        set_global_seed(self.a.seed)
        super()._pre_common()


class TorchCommander(MLCommander):
    def _pre_common(self):
        self.use_gpu = not self.a.cpu and torch.cuda.is_available()
        self.use_multi_gpu = self.use_gpu and torch.cuda.device_count() > 1
        self.device = torch.device('cuda' if self.use_gpu else 'cpu')
        self.mode = 'multi GPU' if self.use_multi_gpu else 'single GPU' if self.use_gpu else 'CPU'
        self.additional_info['mode'] = self.mode
        self.additional_info['device'] = self.device

        self.fmt_loss = '{:.4f}'
        super()._pre_common()

    def _arg_common(self, parser):
        # pylint: disable=unnecessary-lambda
        D = lambda name, value: self.defaults.get(name, value)
        parser.add_argument('--cpu', action='store_true')
        parser.add_argument('-b', '--batch-size', type=int, default=D('batch_size', 8))
        parser.add_argument('--num-workers', type=int, default=D('num_workers', 4))
        parser.add_argument('--lr', type=float, default=D('lr', 0.01))
        parser.add_argument('-e', '--epoch', type=int, default=D('epoch', 50))
        parser.add_argument('--log-dir', default=D('log_dir', 'data/logs'))
        parser.add_argument('--save-period', type=int, default=D('save_period', 25))
        parser.add_argument('--show-fig', action='store_true')
        super()._arg_common(parser)


    def as_loader(self, dataset, **kwargs):
        return DataLoader(
            dataset=dataset,
            batch_size=self.a.batch_size,
            num_workers=self.a.num_workers,
            shuffle=True,
            **kwargs,
        )

    def create_trainer(self, T, model_name, loaders, trainer_name=None, log_dir=None, **kwargs):
        return T(
            model_name=model_name,
            loaders=loaders,
            trainer_name=self.with_suffix(trainer_name or model_name),
            log_dir=log_dir or self.a.log_dir,
            device=self.device,
            save_period=self.a.save_period,
            show_fig=self.a.show_fig,
            **kwargs,
        )

    def create_predictor(self, P, checkpoint, **kwargs):
        return P(
            checkpoint=checkpoint,
            device=self.device,
            batch_size=self.a.batch_size,
            **kwargs,
        )
