import os
import re
import math
import random
from pathlib import Path
import subprocess

import torch
import numpy as np
import matplotlib
from matplotlib import ticker, pyplot as plt
from torch import optim
from torch.optim.lr_scheduler import LambdaLR
from torch.utils.data import DataLoader
from torchvision import transforms
from tqdm import tqdm

from .torch_utils import get_random_states, restore_random_states, pil_to_tensor, tensor_to_pil
from .commander import Commander
from .trainer import Trainer
from .predictor import Predictor



class MLCommander(Commander):
    def with_suffix(self, s):
        if self.args.suffix:
            return f'{s}_{self.args.suffix}'
        return s

    def _arg_common(self, parser):
        self._common_parser.add_argument('--seed', type=int, default=self.defaults.get('seed', 42))
        self._common_parser.add_argument('--suffix', default='')
        super()._arg_common(parser)

    def _pre_common(self):
        random.seed(self.args.seed)
        np.random.seed(self.args.seed)
        torch.manual_seed(self.args.seed)
        torch.random.manual_seed(self.args.seed)
        torch.cuda.manual_seed(self.args.seed)
        torch.backends.cudnn.deterministic = True
        torch.use_deterministic_algorithms = True
        super()._pre_common()


class TorchCommander(MLCommander):
    def _pre_common(self):
        self.use_gpu = not self.args.cpu and torch.cuda.is_available()
        self.use_multi_gpu = self.use_gpu and torch.cuda.device_count() > 1
        self.device = torch.device('cuda' if self.use_gpu else 'cpu')
        self.mode = 'multi GPU' if self.use_multi_gpu else 'single GPU' if self.use_gpu else 'CPU'
        self.additional_info['mode'] = self.mode
        self.additional_info['device'] = self.device

        self.fmt_loss = '{:.4f}'
        super()._pre_common()

    def _arg_common(self, parser):
        # pylint: disable=unnecessary-lambda
        D = lambda name, value: self.defaults.get(name, value)
        parser.add_argument('--cpu', action='store_true')
        parser.add_argument('-b', '--batch-size', type=int, default=D('batch_size', 8))
        parser.add_argument('--num-workers', type=int, default=D('num_workers', 4))
        parser.add_argument('--lr', type=float, default=D('lr', 0.01))
        parser.add_argument('-e', '--epoch', type=int, default=D('epoch', 50))
        parser.add_argument('--save-period', type=int, default=D('save_period', 25))
        parser.add_argument('--show-fig', action='store_true')
        super()._arg_common(parser)


    def as_loader(self, dataset, **kwargs):
        return DataLoader(
            dataset=dataset,
            batch_size=self.args.batch_size,
            num_workers=self.args.num_workers,
            shuffle=True,
            **kwargs,
        )

    def create_trainer(self, T, name, model, loaders, **kwargs):
        return T(
            name=name,
            model=model,
            loaders=loaders,
            device=self.device,
            save_period=self.args.save_period,
            show_fig=self.args.show_fig,
            suffix=self.args.suffix,
            **kwargs,
        )

    def create_predictor(self, P, checkpoint, **kwargs):
        return P(
            checkpoint=checkpoint,
            device=self.device,
            batch_size=self.a.batch_size,
            **kwargs,
        )
