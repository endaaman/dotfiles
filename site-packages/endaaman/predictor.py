import os
import re
import math
import random
import subprocess
from abc import ABCMeta, abstractmethod
from typing import NamedTuple
from collections import OrderedDict
from datetime import datetime

import numpy as np
import matplotlib
from matplotlib import ticker, pyplot as plt
import torch
from torch import optim
from torch.optim.lr_scheduler import LambdaLR
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
from tqdm import tqdm


class Predictor(metaclass=ABCMeta):
    def __init__(self, checkpoint, device='cpu', batch_size=8, **kwargs):
        self.checkpoint = checkpoint

        self.device = device
        self.batch_size = batch_size

        self.model = self.create_model()
        self.prepare(**kwargs)

    def prepare(self, **kwargs):
        pass

    @abstractmethod
    def create_model(self):
        pass

    def eval(self, inputs):
        return self.model(inputs.to(self.device))

    def collate(self, pred, idx):
        return pred

    def transform_image(self, image):
        raise RuntimeError('NEED OVERRIDE')

    def unpack(self, pack):
        inputs, __labels = pack
        return inputs

    def predict(self, loader):
        preds = []
        idx = 0
        for pack in tqdm(loader, leave=False):
            inputs = self.unpack(pack)
            with torch.no_grad():
                oo = self.eval(inputs)
                for o in oo:
                    preds.append(self.collate(o, idx))
                    idx += 1

        return preds

    def predict_images(self, images):
        preds = []
        start = 0
        idx = 0
        t = tqdm(range(0, len(images), self.batch_size))
        for start in t:
            batch = images[start:start+self.batch_size]
            inputs = torch.stack([self.transform_image(i) for i in batch]).to(self.device)
            with torch.no_grad():
                oo = self.eval(inputs)
                for o in oo:
                    preds.append(self.collate(o, idx))
                    idx += 1

            t.set_description(f'{start} ~ {start + self.batch_size} / {len(images)}')
            t.refresh()

        return preds
